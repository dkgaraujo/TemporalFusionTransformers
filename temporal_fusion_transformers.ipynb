{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Experimenting with TFT\"\n",
    "author: Douglas Araujo\n",
    "format: \n",
    "    html:\n",
    "        toc: true\n",
    "        toc-location: right\n",
    "        toc-depth: 4\n",
    "        number-sections: true\n",
    "        code-fold: true\n",
    "        code-tools: true\n",
    "        embed-resources: true\n",
    "bibliography: ref.bib\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes the temporal fusion transformers [@lim2021temporal] architecture, and ports it over to keras 3 while making some punctual improvements, including bringing the notation closer to the one in the paper.\n",
    "\n",
    "The original repository is [here](https://github.com/google-research/google-research/tree/master/tft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 14:16:22.687447: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from fastcore import docments\n",
    "from nbdev.showdoc import show_doc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main characteristics of TFT that make it interesting for nowcasting or forecasting purposes are:\n",
    "\n",
    "- **multi-horizon forecasting**: the ability to output, at each point in time $t$, a sequence of forecasts for $t+h, h > 1$\n",
    "- **quantile prediction**: each forecast is accompanied by a quantile band that communicates the amount of uncertainty around a prediction\n",
    "- **flexible use of different types of inputs**: static inputs (akin to fixed effects), historical input and known future input (eg, important holidays, years that are known to have major sports events such as Olympic games, etc)\n",
    "- **interpretability**: the model learns to select variables from the space of all input variables to retain only those that are globally meaningful, to assign attention to different parts of the time series, and to identify events of significance\n",
    "\n",
    "## Main innovations\n",
    "\n",
    "The present model includes the following innovations:\n",
    "\n",
    "- **Multi-frequency input**\n",
    "\n",
    "- **Context enhancement from lagged target**: the last known values of the target variable are embedded (bag of observations), and this embedding is used similar to the static context enhancement as a starting point for the cell value in the *decoder* LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data\n",
    "\n",
    "The functions below will be tested with simulated and real data. The former helps to illustrate issues like dimensions and overall behaviour of a layer, whereas the latter will demonstrate on a real setting in economics how the input and output data relate to one another.\n",
    "\n",
    "More specifically, the real data used will be a daily nowcasting exercise of monthly inflation. Note that the models will not necessarily perform well, since their use here is for illustration purposes and thus they are not optimised. Also, the dataset is not an ideal one for nowcasting: other variables could also be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download economic data\n",
    "\n",
    "This is a panel dataset. In addition to the time dimension, it can contain any number of categorical dimensions - for example, combine country and sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "\n",
    "df_all = pd.read_csv(\"data/nowcast_dataset_complete_Dec-08-2023.csv\")\n",
    "df_all['index'] = pd.to_datetime(df_all['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['AU', 'CA', 'CH', 'DE', 'FR', 'GB', 'IN', 'JP', 'US']\n",
    "\n",
    "filter_freq_d = df_all['frequency'] == 'd'\n",
    "filter_cty = df_all['country'].isin(countries)\n",
    "filter_dates = df_all['index'] >= '1980-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input = df_all[filter_freq_d & filter_cty & filter_dates].copy()\n",
    "df_input.drop (['Unnamed: 0', 'frequency'], axis=1, inplace=True)\n",
    "df_input.set_index(['index', 'country'], inplace=True) \n",
    "df_input = df_input.unstack('country')\n",
    "df_input.columns = ['__'.join(col).strip() for col in df_input.columns.values]\n",
    "df_input.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_var = 'CPIh'\n",
    "df_target = df_all.loc[\n",
    "    (df_all['frequency'] == 'm') & (df_all['country'].isin(countries)) & filter_dates,\n",
    "    ['index', 'country'] + [target_var]\n",
    "] \\\n",
    "    .set_index(['index', 'country']) \\\n",
    "    .unstack('country') \\\n",
    "    .droplevel(0, axis=1) \\\n",
    "    .dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_12m_pct = (100 * df_target.pct_change(12))\n",
    "df_target_1m_pct = (100 * df_target.pct_change(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| fig-align: center\n",
    "\n",
    "ax = df_target_12m_pct.plot(figsize=(20, 6))\n",
    "ax.axhline(y=0, color='black')\n",
    "ax.set_title(\"Inflation\", fontsize=16, fontstyle='italic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date features\n",
    "\n",
    "In addition to data provided by the user, the model automatically loads categorical features related to each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_features(\n",
    "    date_range, # Range of dates for which to create date features\n",
    "    is_monthly:bool=False # Is the date measured at the monthly frequency?\n",
    ")->pd.DataFrame: # Categorical date features\n",
    "    \"Categorical features for each day in a range of dates\"\n",
    "    if is_monthly:\n",
    "        return pd.DataFrame({\n",
    "        'Month of Year': date_range.month\n",
    "    })\n",
    "    else:\n",
    "        return pd.DataFrame({\n",
    "            'Day of Week': date_range.dayofweek + 1, # This is the only date feature with zeros, which are masked out\n",
    "            'Day of Month': date_range.day,\n",
    "            'Day of Year': date_range.dayofyear,\n",
    "            'Week of Month': (date_range.day - 1) // 7 + 1,\n",
    "            'Week of Year': pd.Index(date_range.isocalendar().week).astype('int32'),\n",
    "            'Month of Year': date_range.month\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(date_features, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "date_features(df_input.index)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the date features in the main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_feat = date_features(df_input.index)\n",
    "date_feat.index = df_input.index\n",
    "df_input = pd.concat([df_input, date_feat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset\n",
    "\n",
    "This step needs to be done somewhat differently than normal datasets: In the validation and test periods, the input data can very well be from the previous chunk (training and validation, respectively).\n",
    "\n",
    "In practice, this means that we just need to split the **dates** at which the nowcasting will take place. Then, a data loading function (see @sec-dataloaders) can read from the whole time series to look back from that date as needed according to the desired time window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = df_input.index.min()\n",
    "end_date = df_input.index.max()\n",
    "cutoff_date_train = pd.to_datetime('2005-01-01')\n",
    "cutoff_date_valid = pd.to_datetime('2020-01-01')\n",
    "\n",
    "dates_train = pd.date_range(start_date, cutoff_date_train - timedelta(days=1))\n",
    "dates_valid = pd.date_range(cutoff_date_train, cutoff_date_valid - timedelta(days=1))\n",
    "dates_test = pd.date_range(cutoff_date_valid, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all input variables that are not available in the training dataset are removed, and only those with at least some information are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = df_input.loc[min(dates_train):max(dates_train)].dropna(axis=1, how='all').columns\n",
    "df_input = df_input[keep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying continuous and categorical variables {#sec-contcat}\n",
    "\n",
    " The model distinguishes continuous from categorical variables if the user does not provide a list of variable names in a simple (simplistic) way: integer-valued variables that start with one are considered categorical, all other are continuous.\n",
    "\n",
    "The criteria that categorical variables start with one is to ensure that the user does not unwarrantedly pass on categorical variables with zero, since zeros are considered to be a padding for variable-length input data.\n",
    "\n",
    "For variables that are naturally valued in integers, such as the count of number of firms, etc, the user can either ensure there is a zero amongst the integer at any time of the **training** input data, or convert these values to floating numbers. Another alternative that might be relevant in some cases is to use the natural logarithm of that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = df_input.select_dtypes(include=['int']).columns\n",
    "float_cols = df_input.select_dtypes(include=['float']).columns\n",
    "\n",
    "# Columns that are float but actually contain integer values starting with one\n",
    "cat_cols = []\n",
    "\n",
    "for col in int_cols:\n",
    "    if min(df_input[col]) > 0:\n",
    "        cat_cols.append(col)\n",
    "\n",
    "for col in float_cols:\n",
    "    if (df_input[col] % 1 == 0).all() and min(df_input[col]) > 0:  # Check if the fractional part is 0 for all values and the lowest integer is 1\n",
    "        cat_cols.append(col)\n",
    "\n",
    "cont_cols = [c for c in df_input.columns if c not in cat_cols]\n",
    "\n",
    "assert len(cont_cols) + len(cat_cols) == df_input.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further, the categorical variables require a dictionary that indicates the cardinality of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the continuous variables\n",
    "\n",
    "The input series need to be scaled, according to the training data mean and standard deviation.\n",
    "\n",
    "The target series will not be scaled because it is already a small number close to zero that is not exploding in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| warning: false\n",
    "\n",
    "scl = StandardScaler()\n",
    "scl.fit(df_input.loc[dates_train.min():dates_train.max(), cont_cols])\n",
    "df_input_scl = pd.DataFrame(\n",
    "    scl.transform(df_input[cont_cols]),\n",
    "    index=df_input.index,\n",
    "    columns=cont_cols\n",
    "    )\n",
    "df_input_scl = pd.concat([df_input_scl, date_feat], axis=1)\n",
    "\n",
    "assert df_input_scl.shape == df_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cardinality of categorical variables\n",
    "\n",
    "Each categorical variable has its own cardinality. This value is important when creating the embedding layer for each variable; see @sec-input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardin_hist = {c: len(df_input_scl[c].unique()) + 1 for c in cat_cols}\n",
    "\n",
    "cardin_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cardinality of the static variable(s) must also be included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardin_stat = dict(Countries=len(df_target.columns) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The country list also requires an encoding/decoding dictionary for subsequent analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_enc_dict = {cty: idx + 1 for idx, cty in enumerate(df_target.columns)}\n",
    "country_dec_dict = {idx: cty for cty, idx in country_enc_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing data\n",
    "\n",
    "\n",
    "Missing data is dealt with by replacing `NaN`s in the input data with zeros. This has two effects:\n",
    "\n",
    "* it prevents embedding categorical variables since zeros are masked out\n",
    "\n",
    "* for the continuous data, the input layer weights do not pick up any information, and the constant (or \"bias\" in machine learning language) is responsible for conveying any information to subsequent neurons.\n",
    "\n",
    "A more sophisticated approach would be to estimate missing data based on other contemporaneous and past data. For simplicity, this approach will not be followed in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously this step needs to be done after the input data is scaled, otherwise the zeros would be wrongly contributing to the mean and standard deviation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_scl.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we remove the input months for which there is no inflation data (eg, due to the one-month growth calculation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_scl = df_input_scl[df_target_1m_pct.dropna().index.min():]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we separate the training, validation and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_input_train = df_input_scl[:dates_train.max()]\n",
    "df_input_valid = df_input_scl[dates_train.max():dates_valid.max()]\n",
    "df_input_test = df_input_scl[dates_valid.max():dates_test.max()]\n",
    "\n",
    "df_input_train.shape[0], df_input_valid.shape[0], df_input_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loaders {#sec-dataloaders}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally a data loader should:\n",
    "\n",
    "* create a pair of input/target data\n",
    "\n",
    "* the input data should contain:\n",
    "\n",
    "    * continuous data from all countries\n",
    "\n",
    "    * categorical date features\n",
    "\n",
    "    * categorical feature of the country (ie, which country it is)\n",
    "\n",
    "    * known future inputs\n",
    "\n",
    "On the known future inputs: those will be essentially the categorical date features, broadcasted until the end of the desired month to be nowcasted (ie, either the current month or a future one). The nowcast will then be the value of inflation at the end of the \"as-of\" month.\n",
    "\n",
    "> Note: so far, the only known future data used by the model are the categorical features from the dates up to the last day of the nowcasted/forecasted month. However, an important known future data for inflation are the central bank policy variables. These are not yet dealth with in this code, but a future version should incorporate an intelligent way for users to input a vector of policy variables, with the dates up until which they would be known. This could be done in a separate DataFrame with policy variables, which would arguably facilitate working with this data separately from all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_nowcasting_data(\n",
    "    df_daily_input:pd.DataFrame,\n",
    "    df_target:pd.DataFrame,\n",
    "    min_context:int=10, # minimum context length in number of daily observations\n",
    "    context_length:int=120, # context length in number of daily observations (leads to padding if not reached in sampling)\n",
    "    num_months:int=12 # number of months (1 is current month)\n",
    "):\n",
    "\n",
    "    # first step: determine the valid dates for sampling\n",
    "    # from the left, they should allow at least `context_length` up until the sampled date\n",
    "    # from the right, they should allow enough room to retrieve all of the target inflation months\n",
    "    # only the dates \"in the middle\" can be sampled\n",
    "    all_dates = df_daily_input.index\n",
    "    earliest_poss_date = all_dates[min_context]\n",
    "\n",
    "    delta_latest_month = num_months - 1\n",
    "    latest_poss_date = all_dates.max() - relativedelta(months=delta_latest_month) + pd.offsets.MonthEnd(0)\n",
    "\n",
    "    dates_for_sampling = df_daily_input.loc[earliest_poss_date:latest_poss_date].index\n",
    "\n",
    "    # sample a random date, context length and country\n",
    "    sampled_day = pd.to_datetime(np.random.choice(dates_for_sampling))\n",
    "    sampled_ctl = np.random.randint(low=min_context, high=context_length) \\\n",
    "        if min_context < context_length \\\n",
    "        else context_length\n",
    "    X_cat_stat = np.random.randint(low=1, high=len(country_enc_dict)+1, size=(1,))\n",
    "\n",
    "    # create the historical observed data\n",
    "    earliest_date = sampled_day - relativedelta(days=sampled_ctl)\n",
    "    df_hist = df_daily_input.loc[earliest_date:sampled_day]\n",
    "    if df_hist.shape[0] < context_length:\n",
    "        df_pad = pd.DataFrame(np.zeros((context_length-df_hist.shape[0], df_hist.shape[1])))\n",
    "        df_pad.columns = df_hist.columns\n",
    "        df_hist = pd.concat([df_pad, df_hist], axis=0, ignore_index=True)\n",
    "    X_cont_hist = df_hist[cont_cols].values\n",
    "    X_cat_hist = df_hist[cat_cols].values\n",
    "\n",
    "    # create the future known data: month of the year\n",
    "    # note: any other known future information of interest should be included here as well\n",
    "    # eg: mon pol committee meeting dates, months of major sports events, etc\n",
    "    # anything that could influence inflation dynamics\n",
    "    target_month = (sampled_day + relativedelta(months=num_months)).replace(day=1) \\\n",
    "        if num_months == 1 \\\n",
    "        else [(sampled_day + relativedelta(months=d)).replace(day=1) for d in range(num_months)]\n",
    "    X_fut = date_features(pd.DataFrame(index=target_month).index, is_monthly=True).values\n",
    "\n",
    "    # create the target variables\n",
    "    y = df_target.loc[target_month, country_dec_dict[int(X_cat_stat)]].values\n",
    "    \n",
    "    X_cat_stat = keras.ops.expand_dims(X_cat_stat, axis=1)\n",
    "    return [X_cont_hist, X_cat_hist, X_fut, X_cat_stat], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(sample_nowcasting_data, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `min_context` not necessarily number of days because of weekends, etc.\n",
    "\n",
    "In practice, this means that the sampled data almost always needs to be padded, even when `min_context` is equal to `context_length`. See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_cont_hist, X_cat_hist, X_fut, X_cat_stat], y = sample_nowcasting_data(\n",
    "    df_daily_input=df_input_scl.loc[:dates_train.max()],\n",
    "    df_target=df_target_1m_pct,\n",
    "    min_context=120,\n",
    "    context_length=120\n",
    ")\n",
    "\n",
    "X_cont_hist.shape, X_cat_hist.shape, X_fut.shape, X_cat_stat.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_cont_hist).plot(legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_samples(\n",
    "    n_samples:int=1000,\n",
    "    **kwargs\n",
    "):\n",
    "    \"Transforms the dataset from tabular format to a dataset used for training the TFT model.\"\n",
    "    X_cont_hist = []\n",
    "    X_cat_hist = []\n",
    "    X_fut = []\n",
    "    X_cat_stat = []\n",
    "    y = []\n",
    "    for i in tqdm(range(n_samples)):\n",
    "        [indiv_cont_hist, indiv_cat_hist, indiv_fut, indiv_cat_stat], indiv_y = sample_nowcasting_data(**kwargs)\n",
    "        X_cont_hist.append(indiv_cont_hist)\n",
    "        X_cat_hist.append(indiv_cat_hist)\n",
    "        X_fut.append(indiv_fut)\n",
    "        X_cat_stat.append(indiv_cat_stat)\n",
    "        y.append(indiv_y)\n",
    "    \n",
    "    X_cont_hist = keras.ops.stack(X_cont_hist, axis=0)\n",
    "    X_cat_hist = keras.ops.stack(X_cat_hist, axis=0)\n",
    "    X_fut = keras.ops.stack(X_fut, axis=0)\n",
    "    X_cat_stat = keras.ops.stack(X_cat_stat, axis=0)\n",
    "    y = keras.ops.stack(y, axis=0)\n",
    "\n",
    "    return [X_cont_hist, X_cat_hist, X_fut, X_cat_stat], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(prepare_data_samples, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function serves the purpose to structure the data in a way that the TFT can ingest, while taking advantage of the number of combinations of sampled data X context size to create a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = prepare_data_samples(\n",
    "    n_samples=1000,\n",
    "    df_daily_input=df_input_scl.loc[:dates_train.max()],\n",
    "    df_target=df_target_1m_pct\n",
    ")\n",
    "\n",
    "valid_data = prepare_data_samples(\n",
    "    n_samples=1000,\n",
    "    df_daily_input=df_input_scl.loc[dates_train.max():dates_valid.max()],\n",
    "    df_target=df_target_1m_pct\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X_cont_hist, X_cat_hist, X_cat_fut, X_cat_stat], y = train_data\n",
    "X_cont_hist.shape, X_cat_hist.shape, X_cat_fut.shape, X_cat_stat.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_cont_hist[0, Ellipsis]).plot(legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the argument `max_context_length_days` cannot promise the user to reach the actual number, since there might be weekends or other dates without any information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For models that will nowcast/forecast more than one month, the argument `delta_month` needs to be a list or an iterator as `range()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the months for which to forecast are February (the current month of the sampled day), March and April, corresponding to the three months indicated in the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All historical time series in the same batch have the same length. This length varies beetween batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture\n",
    "\n",
    "First, common notation is introduced, and then individual components are presented. At the end of this section, the whole model is put together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notation\n",
    "\n",
    "* unique entities: $i \\in (1, \\dots\\, I)$\n",
    "* time periods $t \\in [0, T_i]$\n",
    "  * $k \\geq 1$ lags\n",
    "  * $h \\geq 1$ forecasting period\n",
    "* set of entity-level static covariates: $s_i \\in \\mathbf{R}^{m_s}$\n",
    "* set of temporal inputs: $\\chi_{i, t} \\in \\mathbf{R}^{m_\\chi}$\n",
    "  * $\\chi_{i,t} = [z_{i,t}, x_{i,t}]$\n",
    "    * $z_{i,t} \\in \\mathbf{R}^{m_z}$ are historical inputs\n",
    "    * $x_{i,t} \\in \\mathbf{R}^{m_z}$ are a priori known inputs (eg, days of the week or years that have major sports events)\n",
    "  * $m_\\chi$ is the number of total input variables, where $m_\\chi = m_z + m_x$\n",
    "* target scalars: $y_{i,t}$\n",
    "  * $\\hat{y}_{i,t,q} = f_q(y_{i,t-k:t}, z_{i,t-k:t}, x_{i,t-k:t+h}, s_i)$\n",
    "* hidden unit size (common across all the TFT architecture for convenience): $d_{\\text{model}}$\n",
    "* transformed input of $j$-th variable at time $t$: $\\xi_t^{(j)} \\in \\mathbf{R}^{d_{\\text{model}}}$\n",
    "  * $\\Xi_t = [\\xi_t^{(1)}, \\dots, \\xi_t^{(m_\\chi)}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example data\n",
    "\n",
    "All real data examples below use the same data from @sec-real_data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the fundamental units in the TFT network is the dense layer:\n",
    "\n",
    "$$\n",
    "\\mathbb{Y} = \\phi(\\mathbf{W} x + \\mathbf{b}),\n",
    "$$ {#eq-dense}\n",
    "\n",
    "where $x$ is the input data and $\\mathbb{Y}$ is its output, $\\phi$ is an activation function (when it is applied), $\\mathbf{W} \\in \\mathbf{R}^{(d_{\\text{size}} \\times d_{\\text{inputs}})}$ is a matrix of weights and $\\mathbf{b} \\in \\mathbf{R}^{d_{size}}$ is a vector of biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data transformations {#sec-input}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Transforms all input variables into a latent space\n",
    "\n",
    "All input data, regardless if historical, static or future, are transformed into a feature representation with dimension $d_{\\text{model}}$. In other words, $\\chi_{t}^{(j)}$, variable $j$'s observation at each time period $t$, undergoes an injective mapping $f^{(j)} : \\mathbb{R} \\to \\mathbb{R}^{d_{\\text{model}}}$ for continuous data and $f^{(j)} : \\mathbb{N} \\to \\mathbb{R}^{d_{\\text{model}}}$ for categorical data.\n",
    "\n",
    "If the variable $\\chi_{t}^{(j)}$ is continuous, this transformation is done by $d_{\\text{model}}$ linear regressions, the coefficients of which are determined as part of the neural network training:\n",
    "\n",
    "$$\n",
    "\\xi_t^{(j)} = \\mathbf{W}^{(j)} \\chi_{t}^{(j)} + \\mathbf{b}^{(j)},\n",
    "$$\n",
    "\n",
    "where $\\xi_t^{(j)}, \\mathbf{W}^{(j)}, \\mathbf{b}^{(j)} \\in \\mathbb{R}^{d_{\\text{model}}}$. Note that $\\mathbf{W}^{(j)}, \\mathbf{b}^{(j)}$ are the same for variable $j$ at all time periods (ie, the layer is time-distributed).\n",
    "\n",
    "Conversely, if the $j^{\\text{th}}$ variable is categorical, then the transformation is an embedding. Each embedding layer requires a specific number of different categories, ie the cardinality of the categorical variable. This cardinality is assumed to be stable or decreasing outside of the training period; otherwise a new category would appear at testing time for which the model has not learned an embedding.\n",
    "\n",
    "In any case, it is this embedded data, $\\xi_t^{(j)}$, that is used in all the next steps of the TFT network.\n",
    "\n",
    "See @sec-contcat for details of how the model determines which variables are continuous or categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: hide\n",
    "\n",
    "class MultiInputContEmbedding(keras.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model:int, # Embedding size, $d_\\text{model}$\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Embeds multiple continuous variables, each with own embedding space\"\n",
    "        \n",
    "        super(MultiInputContEmbedding, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MultiInputContEmbedding, self).build(input_shape)\n",
    "\n",
    "        # input_shape: (batch_size, num_time_steps, num_variables)\n",
    "        num_variables = input_shape[-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(num_variables, self.d_model),\n",
    "            initializer='uniform',\n",
    "            name='kernel'\n",
    "        )\n",
    "\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.d_model,),\n",
    "            initializer='zeros',\n",
    "            name='bias'\n",
    "        )\n",
    "    \n",
    "    def call(\n",
    "        self,\n",
    "        inputs # Data of shape: (batch size, num time steps, num variables)\n",
    "    ):     \n",
    "        \"Output shape: (batch size, num time steps, num variables, d_model)\"\n",
    "\n",
    "        # Applying the linear transformation to each time step\n",
    "        output = keras.ops.einsum('bti,ij->btij', inputs, self.kernel)\n",
    "        output += self.bias\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], input_shape[1], input_shape[2], self.d_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(MultiInputContEmbedding.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(MultiInputContEmbedding.call, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "xi_cont_hist = MultiInputContEmbedding(d_model=16)(X_cont_hist)\n",
    "\n",
    "print(\"Input data shape: (batch size / num time steps / num variables)\", X_cont_hist.shape)\n",
    "print(\"Encoded data shape: (batch size / num time steps / num variables / d_model)\", xi_cont_hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: hide\n",
    "\n",
    "class MultiInputCategEmbedding(keras.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model:int, # Embedding size, $d_\\text{model}$\n",
    "        cardinalities:dict, # Variable: cardinality in training data\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Embeds multiple categorical variables, each with own embedding function\"\n",
    "        super(MultiInputCategEmbedding, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.cardinalities = cardinalities\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        super(MultiInputCategEmbedding, self).build(input_shape)\n",
    "        if len(self.cardinalities.keys()) != input_shape[-1]:\n",
    "            raise ValueError(\"`cardinalities` should have as many elements as the input data's variables.\")\n",
    "        \n",
    "        self.embed_layer = {var:\n",
    "            keras.Sequential([\n",
    "                layers.Embedding(\n",
    "                    input_dim=cardin,\n",
    "                    output_dim=self.d_model,\n",
    "                    mask_zero=True,\n",
    "                    name=\"Input_embed_\" + var.replace(\" \", \"_\")\n",
    "                )\n",
    "            ]) for var, cardin in self.cardinalities.items()\n",
    "        }\n",
    "        super(MultiInputCategEmbedding, self).build(input_shape)\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        inputs # Data of shape: (batch size, num time steps, num variables)\n",
    "    ):\n",
    "        \"Output shape: (batch size, num time steps, num variables, d_model)\"\n",
    "        embeds = [\n",
    "            self.embed_layer[var](inputs[:,:,idx])\n",
    "            for idx, var in enumerate(self.cardinalities.keys())\n",
    "        ]\n",
    "        return keras.ops.stack(embeds, axis=2) # keras.ops.concatenate(embeds, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(MultiInputCategEmbedding.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(MultiInputCategEmbedding.call, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this function masks out the data whenever categories are set to zero. This is to ensure that the model can take in variable-sized inputs. Because of this, the model requires inputted categorical data to be added 1 whenever zero is a possible category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note to self: I don't like the approach above where we rely implicitly on the input data's ordering to extract the cardinality. But this is a practical way to get things going. It should be changed to a more robust in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "xi_cat_hist = MultiInputCategEmbedding(\n",
    "    d_model=16, \n",
    "    cardinalities=cardin_hist\n",
    ")(X_cat_hist)\n",
    "\n",
    "print(\"Input data shape: (batch size / num time steps / num variables)\", X_cat_hist.shape)\n",
    "print(\"Encoded data shape: (batch size / num time steps / num variables / d_model)\", xi_cat_hist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "xi_cat_fut = MultiInputCategEmbedding(\n",
    "    d_model=16, \n",
    "    cardinalities={'Month of Year': 12 + 1} # hardcoded because it is always just the months in an year\n",
    ")(X_cat_fut)\n",
    "\n",
    "print(\"Input data shape: (batch size / num time steps / num variables)\", X_cat_fut.shape)\n",
    "print(\"Encoded data shape: (batch size / num time steps / num variables / d_model)\", xi_cat_fut.shape)\n",
    "print(keras.ops.any(keras.ops.isnan(xi_cat_fut)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.ops.expand_dims(X_cat_stat, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "xi_stat = MultiInputCategEmbedding(\n",
    "    d_model=16, \n",
    "    cardinalities=cardin_stat\n",
    ")(X_cat_stat)\n",
    "\n",
    "print(\"Input data shape: (batch size / num time steps / num variables)\", X_cat_stat.shape)\n",
    "print(\"Encoded data shape: (batch size / num time steps (=one) / num variables / d_model)\", xi_stat.shape)\n",
    "print(keras.ops.any(keras.ops.isnan(xi_stat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: hide\n",
    "\n",
    "class InputTFT(keras.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Input layer for the Temporal Fusion Transformer model\"\n",
    "        super(InputTFT, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.flat = layers.Flatten()\n",
    "        self.concat = layers.Concatenate(axis=2)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.cont_hist_embed = MultiInputContEmbedding(\n",
    "            self.d_model,\n",
    "            name=\"embed_continuous_historical_vars\"\n",
    "        )\n",
    "        self.cat_hist_embed = MultiInputCategEmbedding(\n",
    "            self.d_model, \n",
    "            cardinalities=cardin_hist,\n",
    "            name=\"embed_categ_historical_vars\"\n",
    "        )\n",
    "        self.cat_fut_embed = MultiInputCategEmbedding(\n",
    "            self.d_model, \n",
    "            # Note below the same categorical variables are just the months in an year. \n",
    "            # This situation may not apply to all cases.\n",
    "            # More complex models using other categorical future known data might require\n",
    "            # another cardinalities dictionary.\n",
    "            cardinalities={'Month of Year': 12},\n",
    "            name=\"embed_categ_knownfuture_vars\"\n",
    "        )\n",
    "        self.cat_stat_embed = MultiInputCategEmbedding(\n",
    "            self.d_model, \n",
    "            cardinalities=cardin_stat,\n",
    "            name=\"embed_categ_static_vars\"\n",
    "        )\n",
    "        super(InputTFT, self).build(input_shape)\n",
    "\n",
    "    def call(\n",
    "        self, \n",
    "        # List of data with shape: [(batch size, num hist time steps, num continuous hist variables), (batch size, num hist time steps, num categorical hist variables), (batch size, num static variables), (batch size, num future time steps, num categorical future variables)]\n",
    "        input:list \n",
    "    ):\n",
    "        \"\"\"List of output with shape: [\n",
    "            (batch size, num hist time steps, num historical variables, d_model),\n",
    "            (batch size, num future time steps, num future variables, d_model)\n",
    "            (batch size, one, num static variables, d_model),\n",
    "        ]\"\"\"\n",
    "        cont_hist, cat_hist, cat_fut, cat_stat = input\n",
    "        if len(cat_stat.shape) == 2:\n",
    "            cat_stat = keras.ops.expand_dims(cat_stat, axis=-1)\n",
    "\n",
    "        cont_hist = self.cont_hist_embed(cont_hist)\n",
    "        #cont_hist = keras.ops.swapaxes(cont_hist, axis1=2, axis2=3)\n",
    "\n",
    "        cat_hist = self.cat_hist_embed(cat_hist)\n",
    "        #cat_hist = self.flat(cat_hist)\n",
    "            \n",
    "        cat_fut = self.cat_fut_embed(cat_fut)\n",
    "        #cat_fut = self.flat(cat_fut)\n",
    "        \n",
    "        cat_stat = self.cat_stat_embed(cat_stat)\n",
    "        #cat_stat = self.flat(cat_stat)\n",
    "\n",
    "        # (batch size / (num time steps * (num historical + future variables) + num static variables) * embedding size)\n",
    "        hist = self.concat([cont_hist, cat_hist])\n",
    "        \n",
    "        return hist, cat_fut, cat_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(InputTFT.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(InputTFT.call, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "xi_hist, xi_fut, xi_stat = InputTFT()([X_cont_hist, X_cat_hist, X_cat_fut, X_cat_stat])\n",
    "print(\"Encoded historical data shape: (batch size / num hist time steps / num historical variables / d_model)\", xi_hist.shape)\n",
    "print(\"Encoded historical data shape: (batch size / num future time steps / num future variables / d_model)\", xi_fut.shape)\n",
    "print(\"Encoded historical data shape: (batch size / one / num static variables / d_model)\", xi_stat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From now on, whenever relevant the examples with real data will use the $\\xi$ elements created above.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following simplistic model shows how the input layer is used. The goal is to highlight how the data is inputted into a TFT model, by not focusing on its complexity just now.\n",
    "\n",
    "First, it takes up the data. Then, in this simplified model it flattens all inputs and uses a dense layer connected to all embeddings at all time points to output the forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip connection\n",
    "\n",
    "> Adds inputs to layer and then implements layer normalisation\n",
    "\n",
    "$$\n",
    "\\text{LayerNorm}(a + b),\n",
    "$$ {#eq-skip}\n",
    "\n",
    "for $a$ and $b$ tensors of the same dimension and $\\text{LayerNorm}(\\cdot)$ being the layer normalisation (@ba2016layer), ie subtracting $\\mu^l$ and dividing by $\\sigma^l$ defined as:\n",
    "\n",
    "$$\n",
    "\\mu^l = \\frac{1}{H} \\sum_{i=1}^H n_i^l \\quad \\sigma^l = \\sqrt{\\frac{1}{H} \\sum_{i=1}^H (n_i^l - \\mu^l)^2},\n",
    "$$ {#eq-layernorm}\n",
    "\n",
    "with $H$ denoting the number of $n$ hidden units in a layer $l$.\n",
    "\n",
    "* Adding a layer's inputs to its outputs is also called \"skip connection\"\n",
    "* The layer is then normalised [@ba2016layer] to avoid having the numbers grow too big, which is detrimental for gradient transmission\n",
    "  * Layer normalisation uses the same computation both during training and inference times, and is particularly suitable for time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated linear unit (GLU)\n",
    "\n",
    "> Linear layer that learns how much to gate vs let pass through\n",
    "\n",
    "Using input $\\gamma \\in \\mathbb{R}^{d_{\\text{model}}}$ and the subscript $\\omega$ to index weights, \n",
    "\n",
    "$$\n",
    "\\text{GLU}_{\\omega}(\\gamma) = \\sigma(W_{4, \\omega} \\gamma + b_{4, \\omega}) \\odot (W_{5, \\omega} \\gamma + b_{5, \\omega}),\n",
    "$$ {#eq-GLU}\n",
    "\n",
    "where $\\mathbf{W} \\in \\mathbf{R}^{(d_{\\text{model}} \\times d_{\\text{model}})}$ is a matrix of weights and $\\mathbf{b} \\in \\mathbf{R}^{d_{model}}$ is a vector of biases. Importantly, $\\mathbf{W}$ and $\\mathbf{b}$ are indexed with $_{\\omega}$ to denote weight-sharing (within each variable) when the layer is time-distributed.\n",
    "\n",
    "@dauphin2017language introduced GLUs. Their intuition is to train two versions of a dense layer in the same data, but one of them having a sigmoid activation (which outputs values between zero and one), then multiplying each hidden unit.\n",
    "\n",
    "The result could be zero or very close to zero through the Hadamard multipliciation, which in practice means that the network would not be affected by that data (ie, the data $\\gamma$ would be gated out). The first term, with the sigmoid, is the gate that determines what percentage of the linear layer passes through.\n",
    "\n",
    "According to @lim2021temporal, GLUs:\n",
    "\n",
    "* *\"... reduce the vanishing gradient problem for deep architectures by providing a linear path for gradients while retaining non-linear capabilities\"* and\n",
    "* *\"... provide flexibility to suppress any parts of the architecture that are not required for a given dataset\"*\n",
    "\n",
    "The GLU is a key part of the Gated Residual Network, described in @sec-GRN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: hide\n",
    "\n",
    "class GatedLinearUnit(keras.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        dropout_rate:float|None=None, # Dropout rate\n",
    "        use_time_distributed:bool=True, # Apply the GLU across all time steps?\n",
    "        activation:str|callable=None, # Activation function\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Gated Linear Unit dynamically gates input data\"\n",
    "        super(GatedLinearUnit, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_time_distributed = use_time_distributed\n",
    "        self.activation = activation\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GatedLinearUnit, self).build(input_shape)\n",
    "        self.dropout = layers.Dropout(self.dropout_rate) if self.dropout_rate is not None else None\n",
    "        self.activation_layer = layers.Dense(self.d_model, activation=self.activation)\n",
    "        self.gate_layer = layers.Dense(self.d_model, activation='sigmoid')\n",
    "        self.multiply = layers.Multiply()\n",
    "\n",
    "        if self.use_time_distributed:\n",
    "            self.activation_layer = layers.TimeDistributed(self.activation_layer)\n",
    "            self.gate_layer = layers.TimeDistributed(self.gate_layer)\n",
    "\n",
    "    def call(\n",
    "        self, \n",
    "        inputs, \n",
    "        training=None\n",
    "    ):\n",
    "        \"\"\"List of outputs with shape: [\n",
    "            (batch size, ..., d_model),\n",
    "            (batch size, ..., d_model)\n",
    "        ]\"\"\"\n",
    "        if self.dropout is not None and training:\n",
    "            inputs = self.dropout(inputs)\n",
    "\n",
    "        activation_output = self.activation_layer(inputs)\n",
    "        gate_output = self.gate_layer(inputs)\n",
    "        return self.multiply([activation_output, gate_output]), gate_output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GatingLayer, self).get_config()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'use_time_distributed': self.use_time_distributed,\n",
    "            'activation': self.activation\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(GatedLinearUnit.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(GatedLinearUnit.call, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "batch_size = 3\n",
    "n_timesteps = 5\n",
    "n_features = 100\n",
    "d_model = 16\n",
    "\n",
    "# input dimensions: batches / timesteps / features\n",
    "x = np.random.randn(batch_size*n_timesteps*n_features).reshape([batch_size, n_timesteps, n_features]) \n",
    "\n",
    "# output dimensions: batches / timesteps / d_model\n",
    "print(\"GLU output shape: (batch size / num time steps / embedding dim)\", GatedLinearUnit(d_model=16)(x)[0].shape)\n",
    "print(\"GLU gate shape: (batch size / num time steps / embedding dim)\", GatedLinearUnit(d_model=16)(x)[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "# output dimensions: batches / num time steps / num variables / d_model\n",
    "\n",
    "glu = GatedLinearUnit()\n",
    "gated_linear, gate = glu(xi_hist[:10, Ellipsis])\n",
    "print(\"GLU input shape: \", xi_hist[:10, Ellipsis].shape)\n",
    "print(\"GLU output shape: \", gated_linear.shape)\n",
    "print(\"GLU gate shape:\", gate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gated residual network (GRN) {#sec-GRN}\n",
    "\n",
    "$$\n",
    "\\text{GRN}_{\\omega}(a, c) = \\text{LayerNorm}(a + \\text{GLU}_{\\omega}(W_{1, \\omega} \\text{ELU}(W_{2, \\omega} a + b_{2, \\omega} + W_{3, \\omega} c) + b_{1, w}))\n",
    "$$ {#eq-GRN}\n",
    "\n",
    "* Breaking down $\\text{GRN}_{\\omega}(a, c)$:\n",
    "    * *1st step*: $\\eta_{2} = \\text{ELU}(W_{2, \\omega} a + b_{2, \\omega} + W_{3, \\omega} c)$ (where the additional context $c$ might be zero) as in @eq-dense but adapted for the added context if any and with $\\text{ELU}(\\cdot)$ as the activation function,\n",
    "    * *2nd step*: $\\eta_{1} = W_{1, \\omega} \\eta_{2} + b_{1, w}$ as in @eq-dense,\n",
    "    * *3rd step*: $\\text{LayerNorm}(a + \\text{GLU}_{\\omega}(\\eta_{1}))$ as in @eq-skip and @eq-GLU\n",
    "* $\\text{ELU}(\\cdot)$ is the Exponential Linear Unit activation function (@clevert2015fast)\n",
    "    * Unlike ReLUs, ELUs allow for negative values, which pushes unit activations closer to zero at a lower computation complexity, and producing more accurate results\n",
    "* The GRN is a key building block of the TFT\n",
    "    * Helps keep information only from relevant input variables\n",
    "    * Also keeps the model as simple as possible by only applying non-linearities when relevant\n",
    "\n",
    "Note that the GRN can take all types of time series inputs, ie continuous historical, categorical historical and categorical future, but not categorical static data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: hide\n",
    "\n",
    "class GatedResidualNetwork(keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        output_size=None, \n",
    "        dropout_rate=None, \n",
    "        use_time_distributed=True, \n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Gated residual network\"\n",
    "        super(GatedResidualNetwork, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.output_size = output_size if output_size is not None else d_model\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.use_time_distributed = use_time_distributed\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GatedResidualNetwork, self).build(input_shape)\n",
    "        self.dense = layers.Dense(self.output_size)\n",
    "        self.hidden_dense = layers.Dense(self.d_model)\n",
    "        self.hidden_activation = layers.Activation('elu')\n",
    "        self.context_dense = layers.Dense(self.d_model, use_bias=False)\n",
    "        self.gating_layer = GatedLinearUnit(\n",
    "            d_model=self.output_size, \n",
    "            dropout_rate=self.dropout_rate, \n",
    "            use_time_distributed=self.use_time_distributed, \n",
    "            activation=None)\n",
    "        self.add = layers.Add()\n",
    "        self.norm = layers.LayerNormalization()\n",
    "\n",
    "        if self.use_time_distributed:\n",
    "            self.dense = layers.TimeDistributed(self.dense)\n",
    "            self.hidden_dense = layers.TimeDistributed(self.hidden_dense)\n",
    "            self.context_dense = layers.TimeDistributed(self.context_dense)\n",
    "\n",
    "    def call(self, inputs, additional_context=None, training=None):\n",
    "        # Setup skip connection\n",
    "        skip = self.dense(inputs) if self.output_size != self.d_model else inputs\n",
    "        \n",
    "        # 1st step: eta2\n",
    "        hidden = self.hidden_dense(inputs)\n",
    "\n",
    "        # Context handling\n",
    "        if additional_context is not None:\n",
    "            hidden += self.context_dense(additional_context)\n",
    "\n",
    "        hidden = self.hidden_activation(hidden)\n",
    "\n",
    "        # 2nd step: eta1 and 3rd step\n",
    "        gating_layer, gate = self.gating_layer(hidden)\n",
    "        \n",
    "        # Final step\n",
    "        GRN = self.add([skip, gating_layer])\n",
    "        GRN = self.norm(GRN)\n",
    "\n",
    "        return GRN, gate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GatedResidualNetwork, self).get_config()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'output_size': self.output_size,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'use_time_distributed': self.use_time_distributed\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(GatedResidualNetwork.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(GatedResidualNetwork.call, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "batch_size = 3\n",
    "n_timesteps = 5\n",
    "n_features = 16\n",
    "d_model = 16\n",
    "\n",
    "# input dimensions: batches / timesteps / features\n",
    "x = np.random.randn(batch_size*n_timesteps*n_features).reshape([batch_size, n_timesteps, n_features]) \n",
    "\n",
    "grn = GatedResidualNetwork(d_model=d_model)\n",
    "\n",
    "output, gate = grn(x)\n",
    "\n",
    "# output dimensions: batches / timesteps / d_model\n",
    "print(\"GRN output shape: \", output.shape)\n",
    "print(\"GRN gate shape: \", gate.shape)\n",
    "#assert grn.shape == [batch_size, n_timesteps, output_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below uses transformed data $\\xi_t^{(j)}$ for $j=0$ as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "grn = GatedResidualNetwork()\n",
    "output, gate = grn(xi_hist[:,:,0,:])\n",
    "\n",
    "# output dimensions: batches / timesteps / d_model (`output_size`)\n",
    "output.shape, [xi_hist[:,:,0,:].shape[0], xi_hist[:,:,0,:].shape[1], d_model], gate.shape, [xi_hist[:,:,0,:].shape[0], xi_hist[:,:,0,:].shape[1], d_model]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection networks\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{m_{\\chi}} \\upsilon_{\\chi_t}^{(j)} \\tilde{\\xi}_t^{(j)},\n",
    "$$ {#eq-VSN}\n",
    "\n",
    "with $j$ indexing the input variable and $m$ being the number of features, $\\upsilon_{\\chi_t}^{(j)}$ standing for variable $j$'s selection weight, and $\\tilde{\\xi}_t^{(j)}$ defined as:\n",
    "\n",
    "$$\n",
    "\\tilde{\\xi}_t^{(j)} = \\text{GRN}(\\xi_t^{(j)}).\n",
    "$$ {#eq-embed}\n",
    "\n",
    "* In the paper, they are represented in the bottom right of Fig. 2\n",
    "* Note there are separate variable selection networks for different input groups:\n",
    "  * `static_variable_selection`\n",
    "    * does not have static context as input, it already *is* the static information\n",
    "  * `temporal_variable_selection`\n",
    "    * used for both historical and known future inputs\n",
    "    * includes static contexts\n",
    "* Both of these functions take the result of the transformed data, ie embeddings for categorical variables and a linear layer for continuous variables\n",
    "  * static variables are always categorical\n",
    "  * temporal variables can be either categorical or continuous\n",
    "  * in any case, following @lim2021temporal, the resulting transformation is expected to have the same dimension as `d_model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StaticVariableSelection(keras.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        dropout_rate:float=0., \n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Static variable selection network\"\n",
    "        super(StaticVariableSelection, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Define GRNs for the transformed embeddings\n",
    "        self.grns_transformed_embeddings = []  # This will be a list of GRN layers\n",
    "\n",
    "        self.flat = layers.Flatten()\n",
    "        self.softmax = layers.Activation('softmax')\n",
    "        self.mult = layers.Multiply()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(StaticVariableSelection, self).build(input_shape)\n",
    "        \n",
    "        num_static = input_shape[2]\n",
    "\n",
    "        # Define the GRN for the sparse weights\n",
    "        self.grn_sparse_weights = GatedResidualNetwork(\n",
    "            d_model=self.d_model,\n",
    "            output_size=num_static,\n",
    "            use_time_distributed=False\n",
    "        )\n",
    "\n",
    "        for i in range(num_static):\n",
    "            # Create a GRN for each static variable\n",
    "            self.grns_transformed_embeddings.append(\n",
    "                GatedResidualNetwork(self.d_model, use_time_distributed=False)\n",
    "            )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        _, _, num_static, _ = inputs.shape # batch size / one time step (since it's static) / num static variables / d_model\n",
    "\n",
    "        flattened = self.flat(inputs)\n",
    "\n",
    "        # Compute sparse weights\n",
    "        grn_outputs, _ = self.grn_sparse_weights(flattened)\n",
    "        sparse_weights = self.softmax(grn_outputs)\n",
    "        sparse_weights = keras.ops.expand_dims(sparse_weights, axis=-1)\n",
    "\n",
    "        # Compute transformed embeddings\n",
    "        transformed_embeddings = []\n",
    "        for i in range(num_static):\n",
    "            embed, _ = self.grns_transformed_embeddings[i](inputs[:, 0, i:i+1, :])\n",
    "            transformed_embeddings.append(embed)\n",
    "        transformed_embedding = keras.ops.concatenate(transformed_embeddings, axis=1)\n",
    "\n",
    "        # Combine with sparse weights\n",
    "        combined = self.mult([sparse_weights, transformed_embedding])\n",
    "        static_vec = keras.ops.sum(combined, axis=1)\n",
    "\n",
    "        return static_vec, sparse_weights\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(StaticVariableSelectionLayer, self).get_config()\n",
    "        config.update({\n",
    "            'd_model': self.d_model,\n",
    "            'dropout_rate': self.dropout_rate\n",
    "        })\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| output: asis\n",
    "\n",
    "show_doc(StaticVariableSelection.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| output: asis\n",
    "\n",
    "show_doc(StaticVariableSelection.call, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| warning: false\n",
    "\n",
    "svars = StaticVariableSelection()\n",
    "static_vars, static_selection_weights = svars(xi_stat)\n",
    "\n",
    "print(\"xi_t shape: batch size / num time steps (=one) / number of categorical static variables / embedding size\", xi_stat.shape)\n",
    "print(\"Sum of the embeddings of selected variables shape: batch size / embedding size\", static_vars.shape)\n",
    "print(\"Selection weights shape: batch size / number of categorical static variables / one\", static_selection_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: hide\n",
    "\n",
    "class TemporalVariableSelection(keras.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        dropout_rate:float=0., \n",
    "        **kwargs\n",
    "    ):\n",
    "        \"Temporal variable selection\"\n",
    "        super(TemporalVariableSelection, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.mult = layers.Multiply()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(TemporalVariableSelection, self).build(input_shape)\n",
    "        self.batch_size, self.time_steps, self.num_input_vars, self.d_model = input_shape[0]\n",
    "\n",
    "        self.var_sel_weights = GatedResidualNetwork(\n",
    "            d_model=self.d_model,\n",
    "            output_size=self.num_input_vars,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=True,\n",
    "        )\n",
    "        self.softmax = layers.Activation('softmax')\n",
    "    \n",
    "        # Create a GRN for each temporal variable\n",
    "        self.grns_transformed_embeddings = GatedResidualNetwork(\n",
    "                d_model=self.d_model,\n",
    "                dropout_rate=self.dropout_rate,\n",
    "                use_time_distributed=True\n",
    "        )\n",
    "        # self.grns_transformed_embeddings = [\n",
    "        #     GatedResidualNetwork(\n",
    "        #         d_model=self.d_model,\n",
    "        #         dropout_rate=self.dropout_rate,\n",
    "        #         use_time_distributed=True\n",
    "        #     ) for _ in range(self.num_input_vars)\n",
    "        # ]\n",
    "\n",
    "\n",
    "    def call(\n",
    "        self, \n",
    "        inputs, # List of temporal embeddings, static context\n",
    "        training=None\n",
    "    ):\n",
    "        temporal_embeddings, static_context = inputs\n",
    "\n",
    "        flattened_embed = keras.ops.reshape(\n",
    "            temporal_embeddings,\n",
    "            [-1, self.time_steps, self.num_input_vars * self.d_model]\n",
    "        )\n",
    "        parallel_variables = keras.ops.reshape(\n",
    "            temporal_embeddings, \n",
    "            [-1, self.time_steps, self.d_model]\n",
    "        ) # tensor is shaped this way so that a GRN can be applied to each variable of each batch\n",
    "        c_s = keras.ops.expand_dims(static_context, axis=1)\n",
    "\n",
    "        # variable weights\n",
    "        grn_outputs, _ = self.var_sel_weights(flattened_embed, c_s, training=training)\n",
    "        variable_weights = self.softmax(grn_outputs)\n",
    "        variable_weights = keras.ops.expand_dims(variable_weights, axis=2)\n",
    "\n",
    "        # variable combination\n",
    "        # transformed_embeddings = [\n",
    "        #     grn_layer(temporal_embeddings[:, :, i, :], training=training)[0]\n",
    "        #     for i, grn_layer in enumerate(self.grns_transformed_embeddings)\n",
    "        # ]\n",
    "        transformed_embeddings, _ = self.grns_transformed_embeddings(parallel_variables)\n",
    "        transformed_embeddings = keras.ops.reshape(\n",
    "            transformed_embeddings,\n",
    "            [-1, self.time_steps, self.num_input_vars, self.d_model]\n",
    "        )\n",
    "        #transformed_embeddings = keras.ops.stack(transformed_embeddings, axis=2)\n",
    "        temporal_vec = keras.ops.einsum('btij,btjk->btk', variable_weights, transformed_embeddings)\n",
    "        return temporal_vec, keras.ops.squeeze(variable_weights, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| output: asis\n",
    "\n",
    "show_doc(TemporalVariableSelection.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "#| output: asis\n",
    "\n",
    "show_doc(TemporalVariableSelection.call, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main input to `temporal_variable_selection` are the transformed *temporal* variables $\\xi_t^{(j)}$.\n",
    "\n",
    "The selection of the temporal variables also requires the context from the static variables $c_s$, created below by passing `static_vars`, the output from the static variable selection unit (see @eq-static_var_sel), into a GRN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "# static context c_s\n",
    "svars = StaticVariableSelection()\n",
    "xi_stat_selected, _ = svars(xi_stat)\n",
    "static_context_grn = GatedResidualNetwork(use_time_distributed=False)\n",
    "c_s, _ = static_context_grn(xi_stat_selected)\n",
    "\n",
    "# variable selection, historical data\n",
    "tvars_hist = TemporalVariableSelection()\n",
    "hist_sel, hist_weights = tvars_hist([xi_hist[:,:,:5,:], c_s]) # only the first five variables to keep it quick\n",
    "print(\"Temporal variables feature shape: (batch size, num time steps, d_model)\", hist_sel.shape)\n",
    "print(\"Temporal variables weights shape: (batch size, num time steps, num variables (5))\", hist_weights.shape)\n",
    "\n",
    "# variable selection, future data\n",
    "tvars_fut = TemporalVariableSelection()\n",
    "fut_sel, fut_weights = tvars_fut([xi_fut, c_s])\n",
    "print(\"Temporal variables feature shape: (batch size, num time steps, d_model)\", fut_sel.shape)\n",
    "print(\"Temporal variables weights shape: (batch size, num time steps, num variables)\", fut_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence layer (LSTM)\n",
    "\n",
    "This  the `TemporalFeatures` layer implements the following transformation:\n",
    "\n",
    "$$ \\text{LSTM} :\n",
    "\\tilde{\\xi}_{t-k:t}, \\tilde{\\xi}_{t:\\tau_{\\text{max}}} \\in \\mathbb{R}^{k + \\tau_{\\text{max}} X d_{\\text{model}}} \\to \\phi(t, n) \\in \\mathbb{R}^{k + \\tau_{\\text{max}} X d_{\\text{model}}}, n \\in [-k, \\tau_{\\text{max}}],\n",
    "$$ {#eq-seqtoseq}\n",
    "\n",
    "where the starting cell and hidden states of $\\text{LSTM}_{t-k:t}$ are $c_c$ and $c_h$, each calculated as $c_p = GRN(\\xi^{(j)}), p \\in (c, h)$ and $j$ denoting static variables.\n",
    "\n",
    "Finally, the `TemporalFeatures` layer compares the input data $\\tilde{\\xi}_{t-k:\\tau_{\\text{max}}}$ with the non-linear transformation $\\phi(t, n)$, as follows:\n",
    "\n",
    "$$\n",
    "\\tilde{\\phi}(t, n) = \\text{LayerNorm}(\\tilde{\\xi}_{t+n} + \\text{GLU}_{\\tilde{\\phi}}(\\phi(t, n))).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalFeatures(keras.Layer):\n",
    "    def __init__(\n",
    "        self, \n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        dropout_rate:float=0., # Dropout rate\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(TemporalFeatures, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(TemporalFeatures, self).build(input_shape)\n",
    "        self.hist_encoder = layers.LSTM(\n",
    "            units=self.d_model,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            stateful=False,\n",
    "            activation='tanh',\n",
    "            recurrent_activation='sigmoid',\n",
    "            recurrent_dropout=self.dropout_rate,\n",
    "            unroll=False,\n",
    "            use_bias=True\n",
    "        )\n",
    "        self.fut_decoder = layers.LSTM(\n",
    "            units=self.d_model,\n",
    "            return_sequences=True,\n",
    "            return_state=False,\n",
    "            stateful=False,\n",
    "            activation='tanh',\n",
    "            recurrent_activation='sigmoid',\n",
    "            recurrent_dropout=self.dropout_rate,\n",
    "            unroll=False,\n",
    "            use_bias=True\n",
    "        )\n",
    "        self.lstm_glu = GatedLinearUnit(\n",
    "            d_model=self.d_model, # Dimension of the GLU\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            use_time_distributed=True, # Apply the GLU across all time steps?\n",
    "            activation=None # Activation function\n",
    "        )\n",
    "        self.add = layers.Add()\n",
    "        self.l_norm = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        historical_features, future_features, c_h, c_c = inputs\n",
    "        input_embeddings = keras.ops.concatenate(\n",
    "            [historical_features, future_features],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        history_lstm_encoder, state_h, state_c = self.hist_encoder(\n",
    "            historical_features,\n",
    "            initial_state=[\n",
    "                c_h, # short-term state\n",
    "                c_c  # long-term state\n",
    "            ],\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "        future_lstm_decoder = self.fut_decoder(\n",
    "            future_features,\n",
    "            initial_state=[\n",
    "                state_h, # short-term state\n",
    "                state_c  # long-term state\n",
    "            ],\n",
    "            training=training\n",
    "        )\n",
    "        print(history_lstm_encoder.shape, future_lstm_decoder.shape)\n",
    "        # this step concatenates at the time dimension, ie\n",
    "        # the time series of history internal states are now\n",
    "        # concated in sequence with the series of future internal states\n",
    "        # $\\phi(t,n) \\in \\{\\phi(t,-k), \\dots, \\phi(t, \\tau_{\\text{max}})\\}$\n",
    "        lstm_layer = keras.ops.concatenate([history_lstm_encoder, future_lstm_decoder], axis=1)\n",
    "        \n",
    "        # Apply gated skip connection\n",
    "        lstm_layer, _ = self.lstm_glu(\n",
    "            lstm_layer,\n",
    "            training=training\n",
    "        )\n",
    "        outputs = self.add([lstm_layer, input_embeddings])\n",
    "        outputs = self.l_norm(outputs)\n",
    "        # it's the temporal feature layer that is fed into the Temporal Fusion Decoder\n",
    "        # its dimensions are (batch size / num time steps historical + future / hidden size)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_feat = TemporalFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the use of the `TemporalFeatures` layer, we first need to calculate the static contexts used to initialise the historical features' $h$ and $c$ state, respectively $c_h$ and $c_c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| code-fold: show\n",
    "\n",
    "# d_model=16\n",
    "# dropout_rate=0.\n",
    "# svars = StaticVariableSelection(\n",
    "#     d_model=d_model,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     name=\"static_variable_selection\"\n",
    "# )\n",
    "# c_s_grn = GatedResidualNetwork(\n",
    "#     d_model=d_model,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     use_time_distributed=False,\n",
    "#     name=\"static_context\"\n",
    "# )\n",
    "# c_h_grn = GatedResidualNetwork(\n",
    "#     d_model=d_model,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     use_time_distributed=False,\n",
    "#     name=\"static_context\"\n",
    "# )\n",
    "# c_c_grn = GatedResidualNetwork(\n",
    "#     d_model=d_model,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     use_time_distributed=False,\n",
    "#     name=\"static_context\"\n",
    "# )\n",
    "# stat_vars, _ = svars(xi_stat)\n",
    "# c_s, _ = c_s_grn(stat_vars)\n",
    "# c_h, _ = c_h_grn(stat_vars)\n",
    "# c_c, _ = c_c_grn(stat_vars)\n",
    "\n",
    "# print(\"stat_vars shape: (batch size / d_model)\", stat_vars.shape)\n",
    "# print(\"c_s shape: (batch size / d_model)\", c_s.shape)\n",
    "# print(\"c_h shape: (batch size / d_model)\", c_h.shape)\n",
    "# print(\"c_c shape: (batch size / d_model)\", c_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now these variables can be used as inputs for the temporal sequence encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvars_hist = TemporalVariableSelection(\n",
    "#     d_model=d_model,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     name=\"historical_variable_selection\"\n",
    "# )\n",
    "# tvars_fut = TemporalVariableSelection(\n",
    "#     d_model=d_model,\n",
    "#     dropout_rate=dropout_rate,\n",
    "#     name=\"future_variable_selection\"\n",
    "# )\n",
    "# temp_feat = TemporalFeatures()\n",
    "# xi_hist_tilde, _ = tvars_hist([xi_hist, c_s])\n",
    "# xi_fut_tilde, _ = tvars_fut([xi_fut, c_s])\n",
    "\n",
    "# xi_hist_tilde.shape, xi_fut_tilde.shape\n",
    "\n",
    "# temporal_features = temp_feat([xi_hist_tilde, xi_fut_tilde, c_h, c_c])\n",
    "# print(\"temporal_features shape: (batch size / num time steps (hist + fut) / d_model)\", temporal_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(TemporalFeatures.__init__, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(TemporalFeatures.call, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph below plots the temporal futures resulting from the function above, using the first batch of data as an example. Each curve is the time series of one element of the embedding vector, which in turn contains all the relevant information from the time-varying inputs, both categorical and continuous, after being filtered by the network. The black vertical line marks the point at which the temporal futures is relying on future known information.\n",
    "\n",
    "Note that even with these randomly initiated LSTM layers, it is already possible to see the obvious fact that the information content from historical input (left to the vertical line) is different compared to the known future data (ie, information from the dates; to the right of the vertical line).\n",
    "\n",
    "Still, the future part has *some* information, which might be useful in nowcasting or predicting inflation farther out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = pd.DataFrame(temporal_features[0,:,:]).plot(legend=False)\n",
    "# ax.axvline(x=xi_hist_tilde.shape[1], color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial TFT model\n",
    "\n",
    "Let's check out a partial TFT model, with only the building blocks described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartialTFT(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        # quantiles=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        output_size:int=1, # How many periods to nowcast/forecast?\n",
    "        n_head:int=4,\n",
    "        dropout_rate:float=0.1,\n",
    "        random_state:int=1985,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super(PartialTFT, self).__init__(**kwargs)\n",
    "        # self.quantiles = quantiles\n",
    "        self.d_model = d_model\n",
    "        self.output_size = output_size\n",
    "        self.n_head = n_head\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "\n",
    "        keras.utils.set_random_seed(self.random_state)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(PartialTFT, self).build(input_shape)\n",
    "        \n",
    "        self.input_layer = InputTFT(\n",
    "            d_model=self.d_model,\n",
    "            name=\"input\"\n",
    "        )\n",
    "        self.svars = StaticVariableSelection(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            name=\"static_variable_selection\"\n",
    "        )\n",
    "        self.tvars_hist = TemporalVariableSelection(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            name=\"historical_variable_selection\"\n",
    "        )\n",
    "        self.tvars_fut = TemporalVariableSelection(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            name=\"future_variable_selection\"\n",
    "        )\n",
    "        self.static_context_s_grn = GatedResidualNetwork(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False,\n",
    "            name=\"static_context\"\n",
    "        )\n",
    "        self.static_context_h_grn = GatedResidualNetwork(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False,\n",
    "            name=\"static_context\"\n",
    "        )\n",
    "        self.static_context_c_grn = GatedResidualNetwork(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False,\n",
    "            name=\"static_context\"\n",
    "        )\n",
    "        self.temporal_features = TemporalFeatures(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            name=\"LSTM_encoder\"\n",
    "        )\n",
    "        self.add = layers.Add()\n",
    "        self.l_norm = layers.LayerNormalization()\n",
    "        self.flat = layers.Flatten(name=\"flatten\")\n",
    "\n",
    "        output_len = self.output_size # * len(self.quantiles)\n",
    "        # self.output_layer = layers.TimeDistributed(\n",
    "        #     layers.Dense(output_len),\n",
    "        #     name=\"output\"\n",
    "        # )\n",
    "        self.output_layer = layers.Dense(output_len, name=\"output\")\n",
    "    \n",
    "    def call(\n",
    "        self,\n",
    "        inputs\n",
    "    ):\n",
    "        \"Creates the model architecture\"\n",
    "        \n",
    "        # embedding the inputs\n",
    "        cont_hist, cat_hist, cat_fut, cat_stat = inputs\n",
    "        if len(cat_stat.shape) == 2:\n",
    "            cat_stat = keras.ops.expand_dims(cat_stat, axis=-1)\n",
    "            \n",
    "        xi_hist, xi_stat, xi_fut = self.input_layer([cont_hist, cat_hist, cat_stat, cat_fut])\n",
    "\n",
    "        # selecing the static covariates\n",
    "        static_selected_vars, static_selection_weights = self.svars(xi_stat)\n",
    "\n",
    "        # create context vectors from static data\n",
    "        c_s, _ = self.static_context_s_grn(static_selected_vars) # for variable selection\n",
    "        c_h, _ = self.static_context_h_grn(static_selected_vars) # for LSTM state h\n",
    "        c_c, _ = self.static_context_c_grn(static_selected_vars) # for LSTM state c\n",
    "\n",
    "        # temporal variable selection\n",
    "        #print(\"starting hist tvars, with inputs shaped: \", xi_hist.shape, c_s.shape)\n",
    "        hist_selected_vars, hist_selection_weights = self.tvars_hist([xi_hist, c_s])\n",
    "        #print(\"starting fut tvars, with inputs shaped: \", xi_fut.shape, c_s.shape)\n",
    "        fut_selected_vars, fut_selection_weights = self.tvars_fut([xi_fut, c_s])\n",
    "        input_embeddings = keras.ops.concatenate(\n",
    "            [hist_selected_vars, fut_selected_vars],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        #print(\"starting LSTM encoding, with inputs shaped: \", hist_selected_vars.shape, fut_selected_vars, c_h.shape, c_c.shape)\n",
    "        output = self.temporal_features(\n",
    "            [hist_selected_vars, fut_selected_vars, c_h, c_c]\n",
    "        )\n",
    "        \n",
    "        # flatten the outputs (similar to a \"bag of future encodings\")\n",
    "        # otherwise there is an output per future known day\n",
    "        output = self.flat(output[:,output.shape[1]:,:])\n",
    "        output = self.output_layer(output)\n",
    "        #print(\"forward pass complete, shape: \", output.shape)\n",
    "        # define the outputs\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "tft = PartialTFT(\n",
    "    d_model=6,\n",
    "    output_size=train_data[1].shape[-1], \n",
    "    dropout_rate=0.2,\n",
    "    name=\"partial_tft\"\n",
    ")\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "tft.compile(optimizer=optimizer, loss=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = tft.fit(\n",
    "    x=train_data[0], \n",
    "    y=train_data[1], \n",
    "    validation_data=valid_data,\n",
    "    batch_size=100, \n",
    "    epochs=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataloader = DataLoader(data, batch_size=5, shuffle=True)\n",
    "tft.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(data, batch_size=1, shuffle=True)\n",
    "x, y = next(iter(val_dataloader))\n",
    "tft.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.save(\"model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including speech data\n",
    "For now, simply merge the speech embeddings with the daily DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_embeddings = pd.read_csv(\"../data/speech_embeddings.csv\", index_col=\"date\")\n",
    "speech_embeddings.index = pd.to_datetime(speech_embeddings.index)\n",
    "df_input_embed = df_input_scl.join(speech_embeddings, on=\"index\").fillna(0)\n",
    "df_input_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NowcastingData(\n",
    "    df_daily_input=df_input_embed, \n",
    "    df_target=df_target_1m_pct,\n",
    "    max_context_length_days=365,\n",
    "    delta_month=range(12)\n",
    ")\n",
    "\n",
    "tft_speech = PartialTFT(\n",
    "    d_model=8,\n",
    "    output_size=y.shape[-1], \n",
    "    dropout_rate=0.2,\n",
    "    name=\"partial_tft\"\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(data, batch_size=32, shuffle=True)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "tft_speech.compile(optimizer=optimizer, loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "history = tft_speech.fit(batch[0], batch[1], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_speech.save(\"model_speech.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static enrichment\n",
    "\n",
    "This step is responsible for adding static information on the country for which inflation is being nowcasted to the temporal features.\n",
    "\n",
    "This is achieved by a GRN layer as follows:\n",
    "\n",
    "$$\n",
    "\\theta(t, n) = \\text{GRN}_{\\theta}(\\tilde{\\phi}(t, n), c_e)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_enrichment(\n",
    "    temporal_features:keras.KerasTensor, # $\\tilde{\\phi}(t, n)$, temporal features of dimension (batch size / num historical + future time steps / embedding size)\n",
    "    static_context:keras.KerasTensor, # $c_e$, static context enrichment vector of dimensions (batch size / num static vars / embedding size)\n",
    "    d_model:int, # Embedding size, $d_\\text{model}$\n",
    "    dropout_rate:float=0. # Dropout rate\n",
    "):\n",
    "    \"Static enrichment\"\n",
    "    enriched, _ = gated_residual_network(\n",
    "        temporal_features,\n",
    "        d_model=d_model,\n",
    "        dropout_rate=dropout_rate,\n",
    "        use_time_distributed=True,\n",
    "        additional_context=static_context\n",
    "    )\n",
    "    return enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(static_enrichment, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below first creates an static context enrichment vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "static_context_enrichment, _ = gated_residual_network( # c_3\n",
    "    x=xi_stat, # Network inputs\n",
    "    d_model=d_model, # Dimension of the GRN\n",
    "    output_size=d_model, # Size of output layer (if None, same as `d_model`)\n",
    "    dropout_rate=0., # Dropout rate\n",
    "    use_time_distributed=False, # Apply the GRN across all time steps?\n",
    ")\n",
    "static_context_enrichment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and now it is used with the temporal features that are the output of `seq_to_seq` for the static enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_temporal_features = static_enrichment(\n",
    "    temporal_features=temporal_features,\n",
    "    static_context=static_context_enrichment,\n",
    "    d_model=16\n",
    ")\n",
    "temporal_features.shape, enriched_temporal_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention components\n",
    "\n",
    "* Attention mechanisms use relationships between keys $K \\in \\mathbf{R}^{N \\times d_{attention}}$ and queries $Q \\in \\mathbf{R}^{N \\times d_{attention}}$ to scale a vector of values $V \\in \\mathbf{R}^{N \\times d_V}$: $\\text{Attention}(Q, K, V) = A(Q, K) V$\n",
    "    * $N$ is the number of timesteps going into the attention layer (the number of lags $k$ plus the number of periods to be forecasted $\\tau_{\\text{max}}$)\n",
    "    * $A(\\cdot)$ is a normalisation function\n",
    "        * After @vaswani2017attention, the canonical choice for $A(\\cdot)$ is the scaled dot-product: $A(Q, K) = \\text{Softmax}(\\frac{Q K^{T}}{\\sqrt{d_{attention}}} )$\n",
    "    \n",
    "* The TFT uses a modified attention head to enhance the explainability of the model\n",
    "* Specifically, the transformer block (multi-head attention) is modified to:\n",
    "    * share values in each head, and\n",
    "    * employ additive aggregation of all heads\n",
    "* More formally, compare the interpretable multi-head attention (used in this paper) with the canonical multi-head attention:\n",
    "    * $\\text{InterpretableMultiHead}(Q, K, V) = \\tilde{H} W_{H}$, with:\n",
    "        * $\\begin{aligned}\\tilde{H} &= \\tilde{A}(Q, K) V W_V \\\\\n",
    "        &= \\{\\frac{1}{m_H} \\sum^{m_{H}}_{h=1} A(Q W^{(h)}_Q, K W^{(h)}_K) \\} V W_V \\\\\n",
    "        &= \\frac{1}{m_H} \\sum^{m_{H}}_{h=1} \\text{Attention}(Q W^{(h)}_Q, K W^{(h)}_K, V W_V)\n",
    "        \\end{aligned}$\n",
    "    * $\\text{MultiHead}(Q, K, V) = [H_1, \\dots, H_{m_H}] W_H$, with:\n",
    "        * $H_h = \\text{Attention}(Q W^{(h)}_Q, K W^{(h)}_K, V W_V^{(h)}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder mask for self-attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decoder_mask(\n",
    "    self_attention_inputs # Inputs to the self-attention layer\n",
    "):\n",
    "    \"Determines shape of decoder mask\"\n",
    "    len_s = keras.ops.shape(self_attention_inputs)[1] # length of inputs\n",
    "    bs = keras.ops.shape(self_attention_inputs)[0] # batch shape\n",
    "    mask = keras.ops.cumsum(keras.ops.eye(len_s), axis=0)\n",
    "\n",
    "    ### warning: I had to manually implement some batch-wise shape here \n",
    "    ### because the new keras `eye` function does not have a batch_size arg.\n",
    "    ### inspired by: https://github.com/tensorflow/tensorflow/blob/v2.14.0/tensorflow/python/ops/linalg_ops_impl.py#L30\n",
    "    ### <hack>\n",
    "    mask = keras.ops.expand_dims(mask, axis=0)    \n",
    "    mask = keras.ops.tile(mask, (bs, 1, 1))\n",
    "    ### </hack>\n",
    "\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(get_decoder_mask, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "dec = get_decoder_mask(grn)\n",
    "\n",
    "assert dec.shape == (grn.shape[0], grn.shape[1], grn.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that it produces an upper-triangular matrix of ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "dec[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage, real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = get_decoder_mask(temporal_features)\n",
    "\n",
    "print(\"Mask shape: (batch size / num time seos / num time steps)\", mask.shape)\n",
    "\n",
    "mask[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dot product attention layer\n",
    "\n",
    "* This is the same as Eq. (1) of @vaswani2017attention \n",
    "    * except that in this case the dimension of the value vector is the same $d_{\\text{attn}} = d_{\\text{model}} / m_{\\text{Heads}}$ as for the query and key vectors\n",
    "* As discussed in the paper, additive attention outperforms dot product attention for larger $d_{\\text{model}}$ values, so the attention is scaled back to smaller values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(keras.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        attention_dropout:float=0.0 # Will be ignored if `training=False`\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dropout = keras.layers.Dropout(rate=attention_dropout)\n",
    "        self.activation = keras.layers.Activation('softmax')\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        q, # Queries, tensor of shape (?, time, D_model)\n",
    "        k, # Keys, tensor of shape (?, time, D_model)\n",
    "        v, # Values, tensor of shape (?, time, D_model)\n",
    "        mask, # Masking if required (sets Softmax to very large value), tensor of shape (?, time, time)\n",
    "        training=None, # Whether the layer is being trained or used in inference\n",
    "    ):\n",
    "        # returns Tuple (layer outputs, attention weights)\n",
    "        scale = keras.ops.sqrt(keras.ops.cast(keras.ops.shape(k)[-1], dtype='float32'))\n",
    "        attention = layers.Dot(axes=(2, 2))([q, k]) / scale\n",
    "        #attention = keras.ops.einsum(\"bij,bjk->bik\", q, keras.ops.transpose(k, axes=(0, 2, 1))) / scale\n",
    "        if mask is not None:\n",
    "            mmask = keras.layers.Lambda(lambda x: (-1e9) * (1. - keras.ops.cast(x, 'float32')))(mask)\n",
    "            attention = keras.layers.Add()([attention, mmask])\n",
    "        attention = self.activation(attention)\n",
    "        if training:\n",
    "            attention = self.dropout(attention)\n",
    "        output = layers.Dot(axes=(2, 1))([attention, v])\n",
    "        #output = keras.ops.einsum(\"btt,btd->bt\", attention, v)\n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(ScaledDotProductAttention, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage\n",
    "Below is an example of how the `ScaledDotProductAttention` layer works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "batch_size = 3\n",
    "n_timesteps = 5\n",
    "n_features = 13\n",
    "\n",
    "# input dimensions: batches / timesteps / features\n",
    "x_btf = np.random.randn(batch_size*n_timesteps*n_features).reshape([batch_size, n_timesteps, n_features]) \n",
    "\n",
    "# using the same vector for q, k and v just to simplify\n",
    "q=keras.ops.cast(x_btf, 'float32')\n",
    "k=keras.ops.cast(x_btf, 'float32')\n",
    "v=keras.ops.cast(x_btf, 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing without masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "output, attention = ScaledDotProductAttention()(q=q, k=k, v=v, mask=None)\n",
    "output.shape, attention.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and with masking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "output, attention = ScaledDotProductAttention()(q=q, k=k, v=v, mask=get_decoder_mask(q))\n",
    "output[0], attention[0] # both have shape (batch_size, n_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage, real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "mask = get_decoder_mask(enriched_temporal_features)\n",
    "\n",
    "output, attention = ScaledDotProductAttention()(\n",
    "    q=enriched_temporal_features,\n",
    "    k=enriched_temporal_features,\n",
    "    v=enriched_temporal_features,\n",
    "    mask=mask\n",
    ")\n",
    "\n",
    "print(\"attention shape: (batch size / num time steps / embedding size)\", output.shape)\n",
    "print(\"attention shape: (batch size / num time steps / num time steps)\", attention.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attention weights for the future periods are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention[0,-xi_fut.shape[1]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "A small detour to illustrate the softmax function. \n",
    "\n",
    "The $i^{\\text{th}}$ element of $\\text{Softmax}(x)$, with $x \\in \\mathbf{R}^K$ is:\n",
    "\n",
    "$$\n",
    "\\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^K e^{x_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, see the values below for an input vector $x$ ($K=5$ in this example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "x = np.array([-np.Inf, -1., 0., 1., 3.])\n",
    "keras.layers.Activation('softmax')(x)\n",
    "print(\"x = \", x)\n",
    "print(\"exp(x) = \", np.exp(x))\n",
    "print(\"denominator (sum of exp(x_j), j=1,...,K) = \", sum(np.exp(x)))\n",
    "print(\"softmax(x) = \", np.exp(x) / sum(np.exp(x)))\n",
    "print(\"sum of softmax(x)_j, j=1,...,K = \", sum(np.exp(x) / sum(np.exp(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the softmax function really makes the largest numbers stand out from the rest.\n",
    "\n",
    "Note also that $-\\infty$ results in 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretable Multi-head attention\n",
    "\n",
    "* When values are shared in each head and then are aggregated additively, each head can still learn different temporal patterns (from their own unique queries and keys), but with the same input values.\n",
    "    * In other words, they can be interpreted as an ensemble over the attention weights\n",
    "    * the paper doesn't mention this explicitly, but the ensemble is equally-weighted - maybe there is some performance to be gained by having some way to weight the different attention heads 🤔, such as having a linear layer combining them... will explore in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpretableMultiHeadAttention(keras.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_head:int,\n",
    "        d_model:int, # Embedding size, $d_\\text{model}$\n",
    "        dropout_rate:float, # Will be ignored if `training=False`\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_head = n_head\n",
    "        self.d_k = self.d_v = d_model // n_head # the original model divides by number of heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # using the same value layer facilitates interpretability\n",
    "        vs_layer = keras.layers.Dense(self.d_v, use_bias=False, name=\"Shared value\")\n",
    "\n",
    "        # creates list of queries, keys and values across heads\n",
    "        self.qs_layers = self._build_layers(self.d_k, n_head)\n",
    "        self.ks_layers = self._build_layers(self.d_k, n_head)\n",
    "        self.vs_layers = [vs_layer for _ in range(n_head)]\n",
    "\n",
    "        self.attention = ScaledDotProductAttention()\n",
    "        self.w_o = keras.layers.Dense(self.d_v, use_bias=False, name=\"W_v\") # W_v in Eqs. (14)-(16), output weight matrix to project internal state to the original TFT\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        q, # Queries, tensor of shape (?, time, D_model)\n",
    "        k, # Keys, tensor of shape (?, time, D_model)\n",
    "        v, # Values, tensor of shape (?, time, D_model)\n",
    "        mask=None, # Masking if required (sets Softmax to very large value), tensor of shape (?, time, time)\n",
    "        training=None\n",
    "    ):\n",
    "        heads = []\n",
    "        attns = []\n",
    "        for i in range(self.n_head):\n",
    "            qs = self.qs_layers[i](q)\n",
    "            ks = self.ks_layers[i](q)\n",
    "            vs = self.vs_layers[i](v)\n",
    "           \n",
    "            head, attn = self.attention(qs, ks, vs, mask, training=training)\n",
    "            if training:\n",
    "                head = keras.layers.Dropout(self.dropout_rate)(head)\n",
    "            heads.append(head)\n",
    "            attns.append(attn)\n",
    "        head = keras.ops.stack(heads) if self.n_head > 1 else heads[0]\n",
    "\n",
    "        outputs = keras.ops.mean(heads, axis=0) if self.n_head > 1 else head # H_tilde\n",
    "        outputs = self.w_o(outputs)\n",
    "        if training:\n",
    "            outputs = keras.layers.Dropout(self.dropout_rate)(outputs)\n",
    "\n",
    "        return outputs, attn\n",
    "\n",
    "    def _build_layers(self, d:int, n_head:int):\n",
    "        return [keras.layers.Dense(d) for _ in range(n_head)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| output: asis\n",
    "#| echo: false\n",
    "\n",
    "show_doc(InterpretableMultiHeadAttention, title_level=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "imha = InterpretableMultiHeadAttention(n_head=8, d_model=16, dropout_rate=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "grn.shape # B, T, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "mask = get_decoder_mask(grn)\n",
    "mask.shape # shape (batch size / num time steps / num time steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "output, attn = imha(grn, grn, grn, mask)\n",
    "output.shape, attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exampel usage, real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "mask = get_decoder_mask(enriched_temporal_features)\n",
    "\n",
    "output, attention = InterpretableMultiHeadAttention(\n",
    "    n_head=1,\n",
    "    d_model=16,\n",
    "    dropout_rate=0.\n",
    ")(\n",
    "    q=enriched_temporal_features,\n",
    "    k=enriched_temporal_features,\n",
    "    v=enriched_temporal_features,\n",
    "    mask=mask\n",
    ")\n",
    "\n",
    "print(\"attention shape: (batch size / num time steps / embedding size)\", output.shape)\n",
    "print(\"attention shape: (batch size / num time steps / num time steps)\", attention.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together: TFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "class PartialTFT(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        output_size:int=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.input_layer = InputTFT(\n",
    "            d_model=self.d_model,\n",
    "            name=\"Input\"\n",
    "        )\n",
    "        \n",
    "        self.flat = layers.Flatten()\n",
    "        self.concat = layers.Concatenate(axis=-1)\n",
    "        self.dense_hidden = layers.Dense(self.d_model)\n",
    "        self.dense_output = layers.Dense(self.output_size)\n",
    "    \n",
    "    def call(\n",
    "        self,\n",
    "        input:list # List with [continuous historical, categorical historical, categorical static, categorical future data]\n",
    "    ):\n",
    "        cont_hist, cat_hist, cat_stat, cat_fut = input\n",
    "        if len(cat_stat.shape) == 2:\n",
    "            cat_stat = keras.ops.expand_dims(cat_stat, axis=-1)\n",
    "\n",
    "        hist, cat_stat, fut = self.input_layer([cont_hist, cat_hist, cat_stat, cat_fut])\n",
    "\n",
    "        hist = self.flat(hist)\n",
    "        cat_stat = self.flat(cat_stat)\n",
    "        fut = self.flat(fut)\n",
    "\n",
    "        output = self.concat([hist, cat_stat, fut])\n",
    "\n",
    "        output = self.dense_hidden(output)\n",
    "        output = self.dense_output(output)\n",
    "        return output\n",
    "\n",
    "model = PartialTFT(output_size=batch_y.shape[-1])\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "model.fit([batch_cont_hist, batch_cat_hist, batch_cat_stat, batch_cat_fut], batch_y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalFusionTransformer(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        quantiles=[0.05, 0.25, 0.5, 0.75, 0.95],\n",
    "        d_model:int=16, # Embedding size, $d_\\text{model}$\n",
    "        output_size:int=1, # How many periods to nowcast/forecast?\n",
    "        n_head:int=4,\n",
    "        dropout_rate:float=0.1,\n",
    "        random_state:int=1985,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.quantiles = quantiles\n",
    "        self.d_model = d_model\n",
    "        self.output_size = output_size\n",
    "        self.n_head = n_head\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "\n",
    "        keras.utils.set_random_seed(self.random_state)\n",
    "\n",
    "        self.input_layer = InputTFT(\n",
    "            d_model=self.d_model,\n",
    "            output_size=self.output_size\n",
    "        )\n",
    "        self.self_attention = InterpretableMultiHeadAttention(\n",
    "            n_head=self.n_head,\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate\n",
    "        )\n",
    "\n",
    "        output_len = self.output_size * len(self.quantiles)\n",
    "        self.output_layer = layers.TimeDistributed(\n",
    "            layers.Dense(output_len)\n",
    "        )\n",
    "\n",
    "    def call(\n",
    "        self,\n",
    "        inputs,\n",
    "        training=None\n",
    "    ):\n",
    "        \"Creates the model architecture\"\n",
    "\n",
    "        # embedding the inputs\n",
    "        cont_hist, cat_hist, cat_stat, cat_fut = inputs\n",
    "        if len(cat_stat.shape) == 2:\n",
    "            cat_stat = keras.ops.expand_dims(cat_stat, axis=-1)\n",
    "            \n",
    "        hist, cat_stat, fut = self.input_layer([cont_hist, cat_hist, cat_stat, cat_fut])\n",
    "\n",
    "        # selecing the static covariates\n",
    "        static_selected_vars, static_selection_weights = static_variable_selection(\n",
    "            xi_stat, \n",
    "            d_model=d_model, \n",
    "            dropout_rate=0.\n",
    "        )\n",
    "\n",
    "        # create context vectors from static data\n",
    "        static_context_variable_selection, _ = gated_residual_network(\n",
    "            static_selected_vars,\n",
    "            self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False\n",
    "        )\n",
    "        \n",
    "        static_context_enrichment, _ = gated_residual_network(\n",
    "            static_selected_vars,\n",
    "            self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False\n",
    "        )\n",
    "\n",
    "        static_context_state_h, _ = gated_residual_network(\n",
    "            static_selected_vars,\n",
    "            self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False\n",
    "        )\n",
    "\n",
    "        static_context_state_c, _ = gated_residual_network(\n",
    "            static_selected_vars,\n",
    "            self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=False\n",
    "        )\n",
    "\n",
    "        # temporal variable selection\n",
    "        temporal_hist_selected_vars, temporal_hist_selection_weights = temporal_variable_selection(\n",
    "            embedding=xi_hist,\n",
    "            context=static_context_variable_selection,\n",
    "            d_model=d_model, \n",
    "            dropout_rate=0.\n",
    "        )\n",
    "\n",
    "        temporal_fut_selected_vars, temporal_fut_selection_weights = temporal_variable_selection(\n",
    "            embedding=xi_fut,\n",
    "            context=static_context_variable_selection,\n",
    "            d_model=d_model, \n",
    "            dropout_rate=self.dropout_rate\n",
    "        )\n",
    "\n",
    "        # sequence-to-sequence encoding\n",
    "        temporal_features = seq_to_seq(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            historical_features=temporal_hist_selected_vars,\n",
    "            future_features=temporal_fut_selected_vars,\n",
    "            static_context_state_h=static_context_state_h,\n",
    "            static_context_state_c=static_context_state_c\n",
    "        )\n",
    "\n",
    "        # static enrichment\n",
    "        expanded_context = keras.ops.expand_dims(\n",
    "            static_context_enrichment,\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        enriched_temporal_features = static_enrichment(\n",
    "            temporal_features=temporal_features,\n",
    "            static_context=expanded_context,\n",
    "            d_model=self.d_model\n",
    "        )\n",
    "\n",
    "        mask = get_decoder_mask(enriched_temporal_features)\n",
    "\n",
    "        features, self.attn_ = self.self_attention(\n",
    "            q=enriched_temporal_features,\n",
    "            k=enriched_temporal_features,\n",
    "            v=enriched_temporal_features,\n",
    "            mask=mask,\n",
    "            training=training\n",
    "        )\n",
    "\n",
    "        # compare pre-attention features with post\n",
    "        features, _ = apply_gating_layer(\n",
    "            features,\n",
    "            self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            activation=None\n",
    "        )\n",
    "        features = add_and_norm([features, enriched_temporal_features])\n",
    "\n",
    "        # non-linear processing of self-attention output\n",
    "        decoder, _ = gated_residual_network(\n",
    "            features,\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=True\n",
    "        )\n",
    "\n",
    "        # final skip connection\n",
    "        decoder, _ = apply_gating_layer(\n",
    "            decoder, \n",
    "            self.d_model, \n",
    "            activation=None\n",
    "        )\n",
    "        transformer_layer = add_and_norm([decoder, temporal_features])\n",
    "\n",
    "        # define the outputs\n",
    "        return self.output_layer(\n",
    "            transformer_layer[:,xi_hist.shape[1]:,:]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_hist, cat_hist, stat, fut, y = batch_breakdown(batch)\n",
    "\n",
    "tft = TemporalFusionTransformer(output_size=3)\n",
    "output = tft([cont_hist, cat_hist, stat, fut])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: show\n",
    "\n",
    "cont_hist, cat_hist, stat, fut, y = batch_breakdown(batch)\n",
    "\n",
    "tft = TemporalFusionTransformer(output_size=3)\n",
    "tft.compile(optimizer=\"rmsprop\", loss=\"mse\")\n",
    "output = tft.fit([cont_hist, cat_hist, stat, fut], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tft.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalFusionTransformer():\n",
    "    def __init__(\n",
    "        self,\n",
    "        # Data params\n",
    "        time_steps:int,\n",
    "        input_size:int,\n",
    "        output_size:int,\n",
    "        category_counts:int,\n",
    "        n_workers:int, # Number of multiprocessing workers\n",
    "\n",
    "        # TFT params\n",
    "        input_obs_loc,\n",
    "        static_input_loc,\n",
    "        known_regular_input_idx,\n",
    "        known_categorical_input_idx,\n",
    "        column_definition,\n",
    "\n",
    "        # Network params\n",
    "        quantile:list=[0.1, 0.5, 0.9], # List of quantiles the model should forecast\n",
    "        d_model:int=30, # Embedding size, $d_\\text{model}$\n",
    "        dropout_rate:float=0.0, # Dropout ratio (between 0.0, inclusive, and less than 1.0)\n",
    "        num_encoder_steps:int=4,\n",
    "        num_stacks:int=4,\n",
    "        num_heads:int=4,\n",
    "        \n",
    "        # Training params\n",
    "        max_gradient_norm:float=1.0, # \n",
    "        learning_rate:float=0.001,\n",
    "        minibatch_size:int=64,\n",
    "        num_epochs:int=100,\n",
    "        early_stopping_patience:int=5,\n",
    "        use_gpu:bool=True\n",
    "    ):\n",
    "        self.time_steps = time_steps\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size # Number of periods to be forecasted\n",
    "        self.category_counts = category_counts\n",
    "        self.n_workers = n_workers # Number of multiprocessing workers\n",
    "        \n",
    "        self.input_obs_loc = input_obs_loc\n",
    "        self.static_input_loc = static_input_loc\n",
    "        self.known_regular_input_idx = known_regular_input_idx\n",
    "        self.known_categorical_input_idx = known_categorical_input_idx\n",
    "        self.column_definition = column_definition\n",
    "\n",
    "        self.quantile = quantile # List of quantiles the model should forecast\n",
    "        self.d_model = d_model # Size of hidden layer\n",
    "        self.dropout_rate = dropout_rate # Dropout ratio (between 0.0, inclusive, and less than 1.0)\n",
    "        self.num_encoder_steps = num_encoder_steps\n",
    "        self.num_stacks = num_stacks\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.max_gradient_norm = max_gradient_norm\n",
    "        self.learning_rate = learning_rate\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.use_gpu = use_gpu\n",
    "\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def __get_tft_embeddings(\n",
    "        self,\n",
    "        all_inputs # Input tensor of dimensions (batch, time steps, num variables)\n",
    "    ):\n",
    "        # Transform raw inputs to embeddings\n",
    "        # For continuous variables: linear transformation\n",
    "        # For categorical variables: embeddings\n",
    "        \n",
    "        num_categorical_variables = len(self.category_counts)\n",
    "        num_regular_variables = self.input_size - num_categorical_variables\n",
    "\n",
    "        embedding_sizes = [\n",
    "            self.d_model\n",
    "            for i, size in enumerate(self.category_counts)\n",
    "        ]\n",
    "\n",
    "        embeddings = [\n",
    "            keras.Sequential([\n",
    "                layers.InputLayer([self.time_steps]),\n",
    "                layers.Embedding(\n",
    "                    self.category_counts[i],\n",
    "                    embedding_sizes[i],\n",
    "                    input_length=self.time_steps,\n",
    "                    dtype='float32'\n",
    "                )\n",
    "            ])\n",
    "            for i in range(num_categorical_variables)\n",
    "        ]\n",
    "\n",
    "        regular_inputs, categorical_inputs = \\\n",
    "            all_inputs[:, :, :num_regular_variables], \\\n",
    "            all_inputs[:, :, num_regular_variables:]\n",
    "\n",
    "        embedded_inputs = [\n",
    "            embeddings[i](categorical_inputs[Ellipsis, i])\n",
    "            for i in range(num_categorical_variables)\n",
    "        ]\n",
    "\n",
    "        # static inputs\n",
    "        if self._static_input_loc:\n",
    "            st_inp_dense = [\n",
    "                layers.Dense(self.d_model)(\n",
    "                    regular_inputs[:, 0, i:i + 1]\n",
    "                )\n",
    "                for i in range(num_regular_variables)\n",
    "                if i in self._static_input_loc\n",
    "            ]\n",
    "            st_inp_embed = [\n",
    "                embedded_inputs[i][:, 0, :]\n",
    "                for i in range(num_categorical_variables)\n",
    "                if  i + num_regular_variables in self._static_input_loc\n",
    "            ]\n",
    "            static_inputs = st_inp_dense + st_inp_embed\n",
    "        else:\n",
    "            static_inputs = None\n",
    "\n",
    "        # Targets\n",
    "        past_inputs = keras.ops.stack([\n",
    "            dense_layer(\n",
    "                size=self.d_model,\n",
    "                activation=None,\n",
    "                use_time_distributed=True\n",
    "            )(regular_inputs[Ellipsis, i:i + 1])\n",
    "        ], axis=-1)\n",
    "\n",
    "        # past inputs: observed but not known a priori\n",
    "        wired_embeddings = [\n",
    "            embeddings[i](categorical_inputs[:,:,i])\n",
    "            for i in range(num_categorical_variables)\n",
    "            if i not in self._known_categorical_input_idx \\\n",
    "                and i + num_regular_variables not in self._input_obs_loc    \n",
    "        ]\n",
    "        unknown_inputs = [\n",
    "            dense_layer(\n",
    "                size=self.d_model,\n",
    "                activation=None,\n",
    "                use_time_distributed=True\n",
    "            )(regular_inputs[Ellipsis, i:i + 1])\n",
    "            for i in range(regular_inputs.shape[-1])\n",
    "            if i not in self._known_categorical_input_idx \\\n",
    "                and i + num_regular_variables not in self._input_obs_loc    \n",
    "        ]\n",
    "        if wired_embeddings + unknown_inputs:\n",
    "            unknown_inputs = keras.ops.stack(wired_embeddings + unknown_inputs, axis=-1)\n",
    "        else:\n",
    "            unkown_inputs = None\n",
    "\n",
    "        # a priori known inputs\n",
    "        known_regular_inputs = [\n",
    "            dense_layer(\n",
    "                size=self.d_model,\n",
    "                activation=None,\n",
    "                use_time_distributed=True\n",
    "            )(regular_inputs[Ellipsis, i:i + 1])\n",
    "            for i in self._known_regular_input_idx\n",
    "            if i not in self._static_input_loc\n",
    "        ]\n",
    "        known_categorical_inputs = [\n",
    "            embedded_inputs[i]\n",
    "            for i in self._known_categorical_input_idx\n",
    "            if i + num_regular_variables not in self._static_input_loc\n",
    "        ]\n",
    "        known_combined_layer = keras.ops.stack(\n",
    "            known_regular_inputs + known_categorical_inputs,\n",
    "            axis=-1\n",
    "        )\n",
    "\n",
    "        return unknown_inputs, known_combined_layer, past_inputs, static_inputs\n",
    "\n",
    "    def _build_base_graph(self):\n",
    "        # Build the graph, defining the layers of the TFT\n",
    "        \n",
    "\n",
    "        ### <TFTInputs>\n",
    "        all_inputs = layers.Input(\n",
    "            shape=(self.time_steps, self.input_size) # Argument `shape` does not include batch size\n",
    "        )\n",
    "        unknown_inputs, known_combined_layer, past_inputs, static_inputs \\\n",
    "            = self.__get_tft_embeddings(all_inputs)\n",
    "        ### </TFTInputs>\n",
    "\n",
    "        # first we isolate the known future inputs and observed past inputs\n",
    "        if unknown_inputs is not None:\n",
    "            historical_inputs = keras.ops.concatenate([\n",
    "                unknown_inputs[:, :self.num_encoder_steps, :],\n",
    "                known_combined_layer[:, :self.num_encoder_steps, :],\n",
    "                past_inputs[:, :self.num_encoder_steps, :]\n",
    "            ], axis=1)\n",
    "        else:\n",
    "            historical_inputs = keras.ops.concatenate([\n",
    "                known_combined_layer[:, :self.num_encoder_steps, :],\n",
    "                past_inputs[:, :self.num_encoder_steps, :]\n",
    "            ])\n",
    "        \n",
    "        # and then we isolate the known future inputs\n",
    "        future_inputs = known_combined_layer[:, :self.num_encoder_steps, :]\n",
    "\n",
    "        # static vars\n",
    "        static_encoder, static_weights = static_variable_selection(static_inputs)\n",
    "\n",
    "        # Static covariate encoders\n",
    "        # These integrate static features into the network through encoding of context vectors\n",
    "        # that condition the time-varying dynamics\n",
    "        self.static_context_variable_selection = gated_residual_network( # c_s\n",
    "            x=static_encoder, # Network inputs\n",
    "            d_model=self.d_model, # Dimension of the GRN\n",
    "            output_size=self.d_model, # Size of output layer (if None, same as `d_model`)\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            use_time_distributed=False, # Apply the GRN across all time steps?\n",
    "        )\n",
    "        self.static_context_enrichment = gated_residual_network( # c_3\n",
    "            x=static_encoder, # Network inputs\n",
    "            d_model=self.d_model, # Dimension of the GRN\n",
    "            output_size=self.d_model, # Size of output layer (if None, same as `d_model`)\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            use_time_distributed=False, # Apply the GRN across all time steps?\n",
    "        )\n",
    "        self.static_context_state_h = gated_residual_network( # c_h\n",
    "            x=static_encoder, # Network inputs\n",
    "            d_model=self.d_model, # Dimension of the GRN\n",
    "            output_size=self.d_model, # Size of output layer (if None, same as `d_model`)\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            use_time_distributed=False, # Apply the GRN across all time steps?\n",
    "        )\n",
    "        self.static_context_state_c = gated_residual_network( # c_c\n",
    "            x=static_encoder, # Network inputs\n",
    "            d_model=self.d_model, # Dimension of the GRN\n",
    "            output_size=self.d_model, # Size of output layer (if None, same as `d_model`)\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            use_time_distributed=False, # Apply the GRN across all time steps?\n",
    "        )\n",
    "\n",
    "        historical_features, historical_flags, _ = temporal_variable_selection(\n",
    "            embedding=historical_inputs,\n",
    "            context=self.static_context_variable_selection,\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate)\n",
    "        future_features, future_flags, _ = temporal_variable_selection(\n",
    "            embedding=future_inputs,\n",
    "            context=self.static_context_variable_selection,\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate)\n",
    "\n",
    "        # Locality enhancement (Section 4.5.1 in paper) with seq-to-seq layer\n",
    "\n",
    "        temporal_feature_layer = seq_to_seq(\n",
    "            d_model=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            historical_features=historical_features,\n",
    "            future_features=future_features,\n",
    "            static_context_state_c=self.static_context_state_c,\n",
    "            static_context_state_h=self.static_context_state_h\n",
    "        )\n",
    "        # Temporal Fusion Decoder (TFT, Purple box in Fig. 2)\n",
    "        # contains three steps\n",
    "        # TFT 1st step: Static enrichment\n",
    "        #   - enhances the temporal features with static metadata (Eq. 18)\n",
    "        \n",
    "        expanded_static_context_c_e = keras.ops.expand_dims(\n",
    "            self.static_context_enrichment,\n",
    "            axis=1\n",
    "        )\n",
    "        enriched = gated_residual_network( # $\\theta(t, n) = \\text{GRN}_{\\theta}(\\tilde{\\theta}(t, n), c_e)\n",
    "            x=temporal_feature_layer, # from t-k to t+\\tau_max\n",
    "            d_model=self.d_model,\n",
    "            output_size=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=True,\n",
    "            additional_context=expanded_static_context_c_e,\n",
    "            return_gate=False\n",
    "        )\n",
    "\n",
    "        # TFT 2nd step: Temporal self-attention\n",
    "\n",
    "        self_attention_layer = InterpretableMultiHeadAttention(\n",
    "            n_head=self.num_heads,\n",
    "            d_model=self.d_model,\n",
    "            dropout=self.dropout_rate # Will be ignored if `training=False`\n",
    "        )\n",
    "        mask = get_decoder_mask(enriched)\n",
    "        post_attn, self_attention = self_attention_layer( # $B(t) = \\text{IMHA}(\\Theta(t), \\Theta(t), \\Theta(t))$\n",
    "            q=enriched,\n",
    "            k=enriched,\n",
    "            v=enriched,\n",
    "            mask=mask\n",
    "        )\n",
    "        post_attn, _ = apply_gating_layer( # $\\text{GLU}_{\\delta}(\\beta(t, n))$\n",
    "            x=post_attn, # Input tensors (batch first)\n",
    "            d_model=self.d_model, # Dimension of the GLU\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            use_time_distributed=True, # Apply the GLU across all time steps?\n",
    "            activation=None # Activation function\n",
    "        )\n",
    "\n",
    "        # skip connection: decides how much of the attention layer is used\n",
    "        post_attn = add_and_norm([post_attn, enriched]) # \\delta(t, n) = \\text{LayerNorm}(\\theta(t, n) + $\\text{GLU}_{\\delta}(\\beta(t, n)))$\n",
    "\n",
    "        # TFT 3rd step: Position-wise feed-forward\n",
    "        decoder = gated_residual_network(\n",
    "            x=post_attn,\n",
    "            d_model=self.d_model,\n",
    "            output_size=self.d_model,\n",
    "            dropout_rate=self.dropout_rate,\n",
    "            use_time_distributed=True,\n",
    "            additional_context=None,\n",
    "            return_gate=False\n",
    "        )\n",
    "\n",
    "        # final skip connection\n",
    "        decoder, _ = apply_gating_layer(\n",
    "            x=decoder, # Input tensors (batch first)\n",
    "            d_model=self.d_model, # Dimension of the GLU\n",
    "            dropout_rate=self.dropout_rate, # Dropout rate\n",
    "            activation=None # Activation function\n",
    "        )\n",
    "        # the temporal feature layer here is to help the model decide\n",
    "        # how much to skip the Temporal Fusion Decoder altogether\n",
    "        transformer_layer = add_and_norm([decoder, temporal_feature_layer])\n",
    "\n",
    "        # the function also returns the attention components\n",
    "        # for explainability analyses\n",
    "        attention_components = {\n",
    "            \"temporal_attention_weights\": self_attention,\n",
    "            \"variable_selection_weights_static_inputs\": static_weights[Ellipsis, 0],\n",
    "            \"variable_selection_weights_past_inputs\": historical_flags[Ellipsis, 0, :],\n",
    "            \"variable_selection_weights_future_inputs\": future_flags[Ellipsis, 0, :]\n",
    "        }\n",
    "\n",
    "        return transformer_layer, all_inputs, attention_components\n",
    "\n",
    "    def build_model(self):\n",
    "        # Build model and define training losses\n",
    "\n",
    "        transformer_layer, all_inputs, self._attention_components = self._build_base_graph()\n",
    "        outputs = keras.layers.TimeDistributed(\n",
    "            keras.layers.Dense(self.output_size * len(self.quantiles))\n",
    "        )(transformer_layer[Ellipsis, self.num_encoder_steps:, :])\n",
    "        model = keras.Model(inputs=all_inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the TFT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "In this example, we will use a simple inflation panel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingado.utils import list_all_dataflows, load_SDMX_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dflows = list_all_dataflows()\n",
    "# dflows[dflows == 'BIS long consumer prices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpi = load_SDMX_data(\n",
    "    sources={'BIS': 'WS_LONG_CPI'},\n",
    "    keys={'FREQ': 'M'},\n",
    "    params={'startPeriod': 2002}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpi = df_cpi['2002-01-01':'2023-09-01']\n",
    "cpi_cols = df_cpi.dropna(how='all', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only one observation per country, retaining only the ones ending in 628 (in opposition to 771)\n",
    "df_infl = df_cpi[[c for c in cpi_cols if '628' in c and c != 'BIS__WS_LONG_CPI_M__AE__628']].pct_change(periods=1).dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the titles from the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infl.columns = [c.split('__')[2] for c in df_infl.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infl.plot(legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cutoff = '2013-01-01'\n",
    "valid_cutoff = '2020-01-01'\n",
    "df_infl_train, df_infl_valid, df_infl_test = df_infl[:train_cutoff], df_infl[train_cutoff:valid_cutoff], df_infl[valid_cutoff:]\n",
    "df_infl_train = df_infl_train[:-1]\n",
    "df_infl_valid = df_infl_valid[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infl_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "This crucial step involves:\n",
    "* measuring the mean and standard deviation of the inflation of each country in the training dataset\n",
    "* using the values above to standardise the training, validation and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scale = {\n",
    "    'mean': df_infl_train.mean(axis=0),\n",
    "    'std': df_infl_train.std(axis=0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_df(df, scale=train_scale):\n",
    "    norm_dfs = []\n",
    "    for cty in df.columns.tolist():\n",
    "        norm_dfs.append((df[cty] - scale['mean'][cty]) / scale['std'][cty])\n",
    "    return pd.concat(norm_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalise_df(df, scale=train_scale):\n",
    "    renorm_dfs = []\n",
    "    for cty in df.columns.tolist():\n",
    "        renorm_dfs.append((df[cty] * scale['std'][cty]) + scale['mean'][cty])\n",
    "    return pd.concat(renorm_dfs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code below check that it is working:\n",
    "# (renormalise_df(normalise_df(df_infl_train, train_scale)) - df_infl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infl_train_n = normalise_df(df_infl_train)\n",
    "df_infl_valid_n = normalise_df(df_infl_valid)\n",
    "df_infl_test_n = normalise_df(df_infl_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_infl_valid_n.plot(legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A simple dense layer\n",
    "\n",
    "This first model is autoregressive: it takes in $p$ lags of an inflation series $\\pi_i$ (in other words, $\\pi_{i, t-p}, ..., \\pi_{i, t-1}$) to predict the period $\\pi_{i,t}$.\n",
    "\n",
    "Note that the model is very simple:\n",
    "* each country's inflation series is only predicted by its past values\n",
    "* the fully connected linear layer learns to pick up any meaningful non-linear interactions between lags, but there is no intrinsic meaning in the order of the lags\n",
    "* this network will always take in as input a $p$-sized vector of lagged data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple function that will take a data frame and return a (input, output) tuple for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer_io(\n",
    "    df, # Pandas DataFrame with the data\n",
    "    idx:[Int], # DataFrame indedx\n",
    "    col:[str], # Column name\n",
    "    p:Int # Number of lags\n",
    "):\n",
    "    # Return an (input, output) tuple for a dense_layer model\n",
    "    \n",
    "    assert len(idx) == len(col)\n",
    "\n",
    "    batch_X, batch_y = [], []\n",
    "    for i in range(len(idx)):\n",
    "        X = df.iloc[idx[i]:(idx[i]+p)][[col[i]]].values.reshape(-1)\n",
    "        if np.isnan(X).any():\n",
    "            continue\n",
    "        batch_X.append(X)\n",
    "        batch_y.append(df.iloc[idx[i]+p][[col[i]]].values)\n",
    "    \n",
    "    return np.vstack(batch_X), np.vstack(batch_y)\n",
    "\n",
    "    #return df.iloc[idx:(idx+p)][[col]].values.reshape(-1), df.iloc[idx+p+1][[col]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layer_io(df=df_infl_train, idx=[3, 4, 5], col=['BR', 'BR', 'BR'], p=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_select(df, p, n_samples):\n",
    "    max_index = len(df) - p\n",
    "    rand_idx, rand_col = [], []\n",
    "    for _ in range(n_samples):\n",
    "        rand_idx.append(random.randint(0, max_index-2)) # instead of -1 only, we also need to account for the target value\n",
    "        rand_col.append(random.choice(df.columns))\n",
    "    return rand_idx, rand_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000 # with replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 24\n",
    "\n",
    "idx, col = random_select(df_infl_train_n, p=p, n_samples=n_samples)\n",
    "train_samples = dense_layer_io(df=df_infl_train_n, idx=idx, col=col, p=p)\n",
    "\n",
    "idx, col = random_select(df_infl_valid_n, p=p, n_samples=n_samples)\n",
    "valid_samples = dense_layer_io(df=df_infl_valid_n, idx=idx, col=col, p=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_linear = dense_layer(size=p)\n",
    "\n",
    "nn_linear = keras.Sequential([\n",
    "    layers.Input((p,)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(5, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_linear.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_linear.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_linear.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nn_linear(train_samples[0]).shape == train_samples[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dense = nn_linear.fit(\n",
    "    x=train_samples[0],\n",
    "    y=train_samples[1],\n",
    "    batch_size=10,\n",
    "    epochs=500,\n",
    "    validation_data=valid_samples,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history_dense.history['rmse']\n",
    "val_loss = history_dense.history['val_rmse']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'bo-', label='Training RMSE')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation RMSE')\n",
    "plt.title('Training and Validation RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_io(\n",
    "    df, # Pandas DataFrame with the data\n",
    "    idx:[Int], # DataFrame indedx\n",
    "    col:[str], # Column name\n",
    "    p:Int # Number of lags\n",
    "):\n",
    "    # Return an (input, output) tuple for a dense_layer model\n",
    "    \n",
    "    assert len(idx) == len(col)\n",
    "\n",
    "    batch_X, batch_y = [], []\n",
    "    for i in range(len(idx)):\n",
    "        X = df.iloc[idx[i]:(idx[i]+p)].values\n",
    "        X[np.isnan(X)] = 0\n",
    "        batch_X.append(X)\n",
    "        batch_y.append(df.iloc[idx[i]+p][[col[i]]].values)\n",
    "    \n",
    "    return np.vstack(batch_X), np.vstack(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = layers.LSTM(units=64, return_sequences=True, return_state=False)\n",
    "fl = layers.Flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0][:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lstm = keras.Sequential([\n",
    "    layers.LSTM(units=64, return_sequences=True, return_state=False, dropout=0.1),\n",
    "    #layers.LSTM(units=1, return_sequences=False, return_state=False, dropout=0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(15, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nn_lstm(np.expand_dims(train_samples[0], axis=-1)).shape == train_samples[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lstm.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm = nn_lstm.fit(\n",
    "    x=train_samples[0],\n",
    "    y=train_samples[1],\n",
    "    batch_size=10,\n",
    "    epochs=500,\n",
    "    validation_data=valid_samples,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history_lstm.history['rmse']\n",
    "val_loss = history_lstm.history['val_rmse']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'bo-', label='Training RMSE')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation RMSE')\n",
    "plt.title('Training and Validation RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with other countries' inflation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between this and the previous one is that it is not only autoregressive, but also considers past data from other countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_cty_io(\n",
    "    df, # Pandas DataFrame with the data\n",
    "    idx:[Int], # DataFrame indedx\n",
    "    col:[str], # Column name\n",
    "    p:Int # Number of lags\n",
    "):\n",
    "    # Return an (input, output) tuple for a dense_layer model\n",
    "    \n",
    "    assert len(idx) == len(col)\n",
    "\n",
    "    batch_X, batch_y = [], []\n",
    "    for i in range(len(idx)):\n",
    "        X = df.iloc[idx[i]:(idx[i]+p)].values\n",
    "        X[np.isnan(X)] = 0\n",
    "        batch_X.append(X)\n",
    "        batch_y.append(df.iloc[idx[i]+p][[col[i]]].values)\n",
    "    \n",
    "    return np.stack(batch_X, axis=0), np.vstack(batch_y)  #np.vstack(batch_X), np.vstack(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_cty_io(df=df_infl_train, idx=[3, 4, 5], col=['BR', 'BR', 'BR'], p=4)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 24\n",
    "\n",
    "idx, col = random_select(df_infl_train_n, p=p, n_samples=n_samples)\n",
    "train_samples = lstm_cty_io(df=df_infl_train_n, idx=idx, col=col, p=p)\n",
    "\n",
    "idx, col = random_select(df_infl_valid_n, p=p, n_samples=n_samples)\n",
    "valid_samples = lstm_cty_io(df=df_infl_valid_n, idx=idx, col=col, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lstm_cty = keras.Sequential([\n",
    "    layers.LSTM(units=1052, return_sequences=True, return_state=False, dropout=0.1),\n",
    "    layers.LSTM(units=64, return_sequences=True, return_state=False, dropout=0.1),\n",
    "    #layers.LSTM(units=1, return_sequences=False, return_state=False, dropout=0.1),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lstm_cty.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert nn_lstm_cty(train_samples[0]).shape == train_samples[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_lstm_cty.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    metrics=[\n",
    "        keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm_cty = nn_lstm_cty.fit(\n",
    "    x=train_samples[0],\n",
    "    y=train_samples[1],\n",
    "    batch_size=20,\n",
    "    epochs=500,\n",
    "    validation_data=valid_samples,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history_lstm_cty.history['rmse']\n",
    "val_loss = history_lstm_cty.history['val_rmse']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'bo-', label='Training RMSE')\n",
    "plt.plot(epochs, val_loss, 'ro-', label='Validation RMSE')\n",
    "plt.title('Training and Validation RMSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model with date features\n",
    "\n",
    "Repeating date features (eg, day in the week, month, quarter and year, week in the month, quarter and year, month in the quarter and year, and quarter in year) can be embedded and included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn_lstm_datefeat = layers.LSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft = TemporalFusionTransformer(\n",
    "    time_steps=12,\n",
    "    input_size=20,\n",
    "    output_size=4,\n",
    "    category_counts=5,\n",
    "    n_workers=2, # Number of multiprocessing workers\n",
    "\n",
    "    # TFT params\n",
    "    input_obs_loc=24,\n",
    "    static_input_loc=24,\n",
    "    known_regular_input_idx=24,\n",
    "    known_categorical_input_idx=24,\n",
    "    column_definition=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tft.time_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "n_timesteps = 4\n",
    "\n",
    "univariate_x = np.ones(shape=(batch_size, n_timesteps))\n",
    "univariate_x = keras.ops.expand_dims(univariate_x, axis=-1)\n",
    "univariate_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = layers.LSTM(\n",
    "    units=6,\n",
    "    return_sequences=True,\n",
    "    return_state=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_x = lstm(univariate_x)\n",
    "transf_x.shape, keras.ops.concatenate([transf_x, transf_x], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transf_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "source": [
    "# References {.unnumbered}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv_gingado')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "977c2d9435ad3a481cf1bbece8d5ecb19e078de55648a0a0bad32b79c2e18340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
